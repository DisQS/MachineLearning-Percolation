{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import random\n",
    "import os\n",
    "#Pour voir les matrices  en entiers sans troncature\n",
    "import sys\n",
    "import numpy\n",
    "import time \n",
    "import datetime\n",
    "\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "###############################################################################\n",
    "def check_name(path):\n",
    "    #print(L)\n",
    "    global seed_list, max_seed, nbre_images\n",
    "    import re\n",
    "    c=0\n",
    "    N=os.listdir(path)\n",
    "    #print(N)\n",
    "    nbre_file=len(N) #V\n",
    "    del(N)\n",
    "    \n",
    "    result=[0]*nbre_file\n",
    "    seed_list=[0]*nbre_file\n",
    "\n",
    "    B=(name for name in os.listdir(path))\n",
    "\n",
    "    for c in range(nbre_file):\n",
    "          \n",
    "        A=next(B).split('_')[9]      \n",
    "        #print(A)\n",
    "    \n",
    "        regex1 = re.compile('\\d+')\n",
    "        result[c]=re.findall(regex1,A)\n",
    "        c+=1\n",
    "    #print(result)\n",
    "    for j in range(len(result)):\n",
    "        #print(j)\n",
    "        seed_list[j]=int(result[j][0])\n",
    "        j+=1\n",
    "        \n",
    "    max_seed=max(seed_list)\n",
    "    nbre_images=nbre_file/3\n",
    "    \n",
    "            \n",
    "    #print(Z)\n",
    "   \n",
    "    #print(max_seed)\n",
    "    \n",
    "    return max_seed, seed_list, nbre_images\n",
    "\n",
    "###############################################################################\n",
    "def create_directory(path):\n",
    "    import os\n",
    "    #print(os.getcwd())\n",
    "\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory failed, existing file with the same name : \"+str(path))\n",
    "    else:\n",
    "        print (\"Successfully created the directory : \"+str(path))\n",
    "    \n",
    "    return\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def lattice_config(size,seed,p):\n",
    "    global lattice, number_occupied\n",
    "    \n",
    "    print(\"lattice_config START\", datetime.datetime.now())\n",
    "    seed1=np.random.seed(seed)\n",
    "    number_occupied=(size*size)*p\n",
    "    #print(random, type(random))\n",
    "    lattice=np.zeros((size,size), dtype=int)\n",
    "    occupied=0\n",
    "    #while len(list(zip(*lattice.nonzero())))<number_occupied:\n",
    "    while occupied < number_occupied:\n",
    "        #print(len(list(zip(*lattice.nonzero()))))\n",
    "        i=random.randint(0,size-1)\n",
    "        j=random.randint(0,size-1)\n",
    "        if lattice[i,j]==0:\n",
    "            lattice[i,j]=1\n",
    "            occupied+=1\n",
    "#     print(lattice)\n",
    "    print(\"lattice_config END\", datetime.datetime.now())\n",
    "    return lattice, number_occupied\n",
    "\n",
    "###############################################################################       \n",
    "def color_point(cluster,top,side):  \n",
    "     \n",
    " \n",
    "    mid_diag=int(np.ceil(len(cluster/2)))-1\n",
    "    quarter_diag=int(np.ceil(len(cluster)/3))-1  \n",
    "    center=cluster[mid_diag][mid_diag]\n",
    "    quarter=cluster[quarter_diag][quarter_diag]\n",
    "    three_quarter=cluster[-(quarter_diag+1)][-(quarter_diag+1)]\n",
    "    anti_quarter=cluster[(quarter_diag)][-(quarter_diag+1)]\n",
    "    anti_three_quarter=cluster[-(quarter_diag+1)][quarter_diag]\n",
    "    center_b=0\n",
    "    quarter_b=0\n",
    "    three_quarter_b=0\n",
    "    anti_quarter_b=0\n",
    "    anti_three_quarter_b=0  \n",
    "    if top!=set():\n",
    "        for i in range(len(top)):\n",
    "            num_cluster=list(top)[i]\n",
    "            if center==num_cluster:\n",
    "                center_b=1\n",
    "            if quarter_b==num_cluster:\n",
    "                quarter_b=1\n",
    "            \n",
    "            if three_quarter==num_cluster:\n",
    "                three_quarter_b=1\n",
    "            \n",
    "            if anti_quarter==num_cluster:\n",
    "                anti_quarter_b=1\n",
    "            \n",
    "            if anti_three_quarter==num_cluster:\n",
    "                anti_three_quarter_b=1\n",
    "\n",
    "    if side!=set():\n",
    "         for j in range(len(side)):\n",
    "            num_cluster=list(side)[j]\n",
    "            if center==num_cluster:\n",
    "                center_b=1\n",
    "            if quarter==num_cluster:\n",
    "                quarter_b=1\n",
    "            \n",
    "            if three_quarter==num_cluster:\n",
    "                three_quarter_b=1\n",
    "            \n",
    "            if anti_quarter==num_cluster:\n",
    "                anti_quarter_b=1\n",
    "            \n",
    "            if anti_three_quarter==num_cluster:\n",
    "                anti_three_quarter_b=1\n",
    "\n",
    "    return quarter_b,three_quarter_b,anti_quarter_b,center_b,anti_three_quarter_b\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cluster_matrix(x, y, n_clusters, N, lattice,cluster, sizes):\n",
    "    stack=[(x,y)]\n",
    "\n",
    "    while len(stack)>0:\n",
    "\n",
    "        x,y=stack.pop(-1)\n",
    "\n",
    "        if lattice[x,y] == 1 and cluster[x,y]==-1:\n",
    "            cluster[x,y] = n_clusters\n",
    "            sizes[n_clusters] += 1     #augmente le nombre de site du cluster\n",
    "            if y+1 < N:\n",
    "                stack.append((x,y+1))\n",
    "\n",
    "            if y-1 >= 0:\n",
    "\n",
    "                stack.append((x,y-1))\n",
    "\n",
    "            if x+1 < N:\n",
    "\n",
    "                stack.append((x+1,y))\n",
    "\n",
    "            if x-1 >= 0:\n",
    "                stack.append((x-1,y))\n",
    "\n",
    "\n",
    "################################################################\n",
    "\n",
    "def cluster_matrix_pbc(x, y, n_clusters, N, lattice,cluster, sizes):\n",
    "    stack=[(x,y)]\n",
    "#     print('stack',stack, 'n_clusters',n_clusters)\n",
    "#     print('-------')\n",
    "    while len(stack)>0:\n",
    "#         print('stack',stack)\n",
    "        x,y=stack.pop(-1)\n",
    "#         print('x','y',x,y,stack)\n",
    "#         print('------------')\n",
    "#         boo=(x==0)\n",
    "#         lat1=(lattice[N-1,y]==1)\n",
    "#         lat2=(lattice[x,N-1]==1)\n",
    "#         print('boo',boo)\n",
    "#         print('lat1',lat1,'lat2',lat2)\n",
    "        if lattice[x%N,y%N] == 1 and cluster[x%N,y%N]==-1:\n",
    "            cluster[x%N,y%N] = n_clusters\n",
    "            sizes[n_clusters] += 1     #augmente le nombre de site du cluster\n",
    "\n",
    "            stack.append((x,(y+1%N)))\n",
    "#                 print('stack1',stack)\n",
    "#             if y-1 >= 0:\n",
    "#                 print('loop2')\n",
    "            stack.append((x,(y-1)%N))\n",
    "#                 print('stack2',stack)\n",
    "\n",
    "#             if x+1 < N:\n",
    "#                 print('loop3')\n",
    "            stack.append(((x+1)%N,y))\n",
    "#                 print('stack3',stack)\n",
    "#             if x-1 >= 0:\n",
    "#                 print('loop4')\n",
    "            stack.append(((x-1)%N,y))\n",
    "#         print(test)\n",
    "\n",
    "###############################################################################\n",
    "def size_spanning_cluster_old(spanning_set, cluster):\n",
    "    global size_spanning\n",
    "    size_spanning=0\n",
    "    nnz1=cluster.nonzero()\n",
    "    for k in range(len(spanning_set)):\n",
    "        for i, j in zip(*nnz1):\n",
    "            if cluster[i,j] ==list(spanning_set)[k]:\n",
    "                size_spanning+=1\n",
    "                \n",
    "    return size_spanning\n",
    "    \n",
    "##############################################################################\n",
    "def size_spanning_cluster(spanning_set,cluster,cluster_pbc_int):\n",
    "    global size_spanning\n",
    "    size=[]\n",
    "    size_spanning=0\n",
    "    span=list(spanning_set)\n",
    "    n_cluster_pbc_int, counts = numpy.unique(cluster_pbc_int, return_counts=True)\n",
    "    zip_lists=list(zip( n_cluster_pbc_int, counts))\n",
    "    for k in range(len(spanning_set)):\n",
    "        for i in range(len(zip_lists)):\n",
    "            if zip_lists[i][0]==span[k]:\n",
    "                size.append(zip_lists[i][1])\n",
    "    if len(size)>1:\n",
    "        size_spanning=max(size)\n",
    "        \n",
    "    return size_spanning\n",
    "\n",
    "##############################################################################\n",
    "def correlation_function_pbc_new_diagonal(lattice,l,n_clusters,seed):\n",
    "    from math import sqrt\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    start50=time.time()\n",
    "\n",
    "    square_distance=np.zeros(l**2)\n",
    "    corr2=np.zeros(l**2)\n",
    "    corr_max_cluster=np.zeros(l**2)\n",
    "    \n",
    "    y_func=np.zeros(l**2)\n",
    "    div_pbc=np.zeros(l**2)\n",
    "    x_pbc_max_cluster=np.zeros(l**2)\n",
    "    div_pbc_max_cluster=np.zeros(l**2)\n",
    "\n",
    "    print('start correlation function',datetime.datetime.now())\n",
    "\n",
    "    new_occupied = lattice.nonzero()\n",
    "    new_occ=zip(*new_occupied)\n",
    "\n",
    "    for y0 in range(l):\n",
    "        for x0 in range(l):\n",
    "\n",
    "            for y1 in range(y0,l):\n",
    "                if y1==y0:\n",
    "\n",
    "                    for x1 in range(x0,l):\n",
    "\n",
    "                        x_distance=abs(x0-x1)\n",
    "                        y_distance=abs(y0-y1)\n",
    "                        \n",
    "  \n",
    "\n",
    "                        \n",
    "                        if x_distance>(l/2):\n",
    "                            x_distance=abs(l-x_distance) \n",
    "                        if y_distance>(l/2):\n",
    "                            y_distance=abs(l-y_distance) \n",
    "\n",
    "                \n",
    "                        distance=x_distance**2+ y_distance**2       \n",
    "                        \n",
    "                        div_pbc[distance]+=1\n",
    "                        if x0!=x1 or y0!=y1:\n",
    "                            div_pbc[distance]+=1\n",
    "                    \n",
    "                        if square_distance[distance]!=distance:\n",
    "                            square_distance[distance]=distance\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        if lattice[y0,x0]!=0 and lattice[y1,x1]!=0 and lattice[y0,x0]==lattice[y1,x1] : \n",
    "                            corr2[distance]+=1\n",
    "\n",
    "                            if x0!=x1 or y0!=y1:\n",
    "                                corr2[distance]+=1\n",
    "                        if lattice[y0,x0]==n_clusters:\n",
    "                            div_pbc_max_cluster[distance]+=1\n",
    "                            if x0!=x1 or y0!=y1:\n",
    "                                div_pbc_max_cluster[distance]+=1\n",
    "\n",
    "                            if lattice[y0,x0]!=0 and  lattice[y1,x1]!=0 and lattice[y0,x0]==lattice[y1,x1]: \n",
    "                                corr_max_cluster[distance]+=1\n",
    "                                if x0!=x1 or y0!=y1:\n",
    "                                    corr_max_cluster[distance]+=1\n",
    "\n",
    "                    \n",
    "                else:\n",
    "#                         print('loop y1!=y0')\n",
    "                    for x1 in range(l): \n",
    "#                             print('x1',x1)\n",
    "                        x_distance=abs(x0-x1)\n",
    "                        y_distance=abs(y0-y1)\n",
    "                        \n",
    "\n",
    "                        if x_distance>(l/2):\n",
    "                            x_distance=abs(l-x_distance)\n",
    "\n",
    "                        \n",
    "                        if y_distance>(l/2):\n",
    "                            y_distance=abs(l-y_distance) \n",
    "\n",
    "                \n",
    "                        distance= x_distance**2+ y_distance**2\n",
    "#                     print('distance',distance)       \n",
    "                        \n",
    "                        div_pbc[distance]+=1\n",
    "                        if x0!=x1 or y0!=y1:\n",
    "                            div_pbc[distance]+=1\n",
    "                                      \n",
    "                        if square_distance[distance]!=distance:\n",
    "                            square_distance[distance]=distance\n",
    "#                                 print(square_distance)\n",
    "                                      \n",
    "                                    \n",
    "                        if lattice[y0,x0]!=0 and lattice[y1,x1]!=0 and lattice[y0,x0]==lattice[y1,x1]: \n",
    "                            corr2[distance]+=1\n",
    "#                                 print('corr2',corr2)\n",
    "                            if x0!=x1 or y0!=y1:\n",
    "                                corr2[distance]+=1\n",
    "                        if lattice[y0,x0]==n_clusters:\n",
    "                            div_pbc_max_cluster[distance]+=1\n",
    "                            if x0!=x1 or y0!=y1:\n",
    "                                div_pbc_max_cluster[distance]+=1\n",
    "#                         print(div_pbc_max_cluster)\n",
    "                            if lattice[y0,x0]!=0 and lattice[y1,x1]!=0 and lattice[y0,x0]==lattice[y1,x1]: \n",
    "                                corr_max_cluster[distance]+=1\n",
    "                                if x0!=x1 or y0!=y1:\n",
    "                                    corr_max_cluster[distance]+=1\n",
    "#                             print(x_pbc_max_cluster)\n",
    "        \n",
    "    end50=time.time()-start50\n",
    "    print('end correlation function',end50)\n",
    "                        \n",
    "\n",
    "    length=len(div_pbc)\n",
    "                                      \n",
    "\n",
    "    \n",
    "    sqrt_distance=[sqrt(square_distance[h]) for h in range(len(square_distance))]\n",
    "    sqrt_distance=np.array(sqrt_distance)\n",
    "    print('len sqrt distance',len(sqrt_distance))\n",
    "    #G.insert(0,0)\n",
    "    \n",
    "    average=[o/l for o,l in zip(corr2,div_pbc) ]\n",
    "    average=np.array(average)\n",
    "    index_max_corr=np.max(np.nonzero(corr2))\n",
    "    corr3=corr2[:index_max_corr+1]\n",
    "    index = np.where(corr3 == 0)[0]  #np.argwhere(np.isnan(W))\n",
    "    correlation_value=np.delete(average,index)\n",
    "    new_corr_before_average=np.delete(corr3,index)\n",
    "    new_distance=np.delete(sqrt_distance,index)\n",
    "    new_distance=np.delete(sqrt_distance,np.argwhere(sqrt_distance==0))\n",
    "    \n",
    "    new_distance=np.insert(new_distance, 0, 0)\n",
    "    \n",
    "#     print('new_distance',new_distance,len(new_distance))\n",
    "    index_max=np.max(np.nonzero(new_corr_before_average))\n",
    "    len_zero=len(new_distance)-(index_max+1)\n",
    "    new_average=np.concatenate((correlation_value[:index_max+1],np.zeros(len_zero)))\n",
    "    new_corr_before_average=np.concatenate((new_corr_before_average[:index_max+1],np.zeros(len_zero)))\n",
    "    correlation_value=np.concatenate((correlation_value[:index_max+1],np.zeros(len_zero)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    average_largest=[o/l for o,l in zip(corr_max_cluster,div_pbc) ]\n",
    "    average_largest=np.array(average_largest)\n",
    "    index_max_corr_largest=np.max(np.nonzero(corr_max_cluster))\n",
    "    corr3_largest=corr_max_cluster[:index_max_corr_largest+1]\n",
    "    \n",
    "    index_largest = np.where(corr3_largest == 0)[0]  #np.argwhere(np.isnan(W))\n",
    "    correlation_value_largest=np.delete(average_largest,index_largest)\n",
    "    new_corr_before_average_largest=np.delete(corr3_largest,index_largest)\n",
    "    new_distance_largest=np.delete(sqrt_distance,index_largest)\n",
    "    new_distance_largest=np.delete(sqrt_distance,np.argwhere(sqrt_distance==0))\n",
    "    \n",
    "    new_distance_largest=np.insert(new_distance_largest, 0, 0)\n",
    "    \n",
    "#     print('new_distance',new_distance,len(new_distance))\n",
    "    index_max_largest=np.max(np.nonzero(new_corr_before_average_largest))\n",
    "    len_zero_largest=len(new_distance_largest)-(index_max_largest+1)\n",
    "    new_average_largest=np.concatenate((correlation_value_largest[:index_max_largest+1],np.zeros(len_zero_largest)))\n",
    "    new_corr_before_average_largest=np.concatenate((new_corr_before_average_largest[:index_max_largest+1],np.zeros(len_zero_largest)))\n",
    "    correlation_value_largest=np.concatenate((correlation_value_largest[:index_max_largest+1],np.zeros(len_zero_largest)))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    end6=time.time()-start50\n",
    "    print('end correlation function',end6)\n",
    "    \n",
    "    \n",
    "    pl.plot(new_distance,new_corr_before_average,label='g(r) every clusters')\n",
    "    pl.legend(loc='best')\n",
    "    pl.xlabel('distance r')\n",
    "    pl.ylabel('correlation function g(r)')\n",
    "    pl.savefig('corr_before_average.png')\n",
    "    pl.close()\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "   \n",
    "    pl.plot(new_distance,new_average,label='g(r) every clusters')\n",
    "    pl.legend(loc='best')\n",
    "    pl.xlabel('distance r')\n",
    "    pl.ylabel('correlation function g(r)')\n",
    "    pl.savefig('corr_after_average_bis.png')\n",
    "    pl.close()\n",
    "    \n",
    "    return new_distance,correlation_value, new_distance_largest,correlation_value_largest, new_corr_before_average\n",
    "#################################################################################\n",
    "def size_max(order_pbc,n_clusters):\n",
    "    \n",
    "    L=order_pbc\n",
    "    values=[]\n",
    "    keys=[]\n",
    "#     print(L)\n",
    "    for k, v in L.items():\n",
    "        if k!=-1:\n",
    "            keys.append(k)\n",
    "            values.append(v)\n",
    "    max_clus=max(values)\n",
    "    max_n_clus=n_clusters\n",
    "    \n",
    "    return max_clus, max_n_clus\n",
    "\n",
    "\n",
    "################################################################################\n",
    "def mapping_cluster(cluster_nan,cluster_pbc_int,n_perco):\n",
    "   \n",
    "    mapping = dict(zip(cluster_nan.flat,cluster_pbc_int.flat))\n",
    "    keys_mapping=mapping.keys()\n",
    "    values_mapping=mapping.values()\n",
    "    v=[p for p in values_mapping if p!=0]\n",
    "    k=list(filter(lambda v: v==v, keys_mapping))\n",
    "    zip_keys_values=list(zip(k,v))\n",
    "    new_n=[]\n",
    "    \n",
    "    for i in range(0,len(zip_keys_values)):\n",
    "        if (zip_keys_values[i][0] in n_perco) and (zip_keys_values[i][1] not in new_n):\n",
    "            new_n.append(zip_keys_values[i][1])\n",
    "\n",
    "    return new_n\n",
    "    \n",
    "    \n",
    "###############################################################################                        \n",
    "                        \n",
    "def correlation_l(distance_to_site,Correlation_func, size_sys,proba_span,proba_largest,p):\n",
    "    \n",
    "    from math import sqrt \n",
    "    start=time.time()\n",
    "    correlation=0\n",
    "    sq_corr_l=0\n",
    "    denom=0\n",
    "    correlation_large=0\n",
    "    denom_large=0\n",
    "    for i in range(len(distance_to_site)):\n",
    "        correlation+= ((distance_to_site[i]**2)*(Correlation_func[i]))#-proba_largest))\n",
    "        correlation_large+= ((distance_to_site[i]**2)*(Correlation_func[i]-proba_largest))\n",
    "        \n",
    "                    \n",
    "        denom+=(Correlation_func[i])#-proba_largest)\n",
    "        denom_large+=(Correlation_func[i]-proba_largest)\n",
    "        \n",
    "    \n",
    "    sq_corr_l=(correlation_large/(denom_large))\n",
    "        \n",
    "    \n",
    "#         print('proba',proba_span)\n",
    "#         print('corr',correlation,'denom', denom)\n",
    "    if sq_corr_l==0:\n",
    "        correlation_length=0\n",
    "    elif sq_corr_l<0:\n",
    "        correlation_length=0\n",
    "#         print(i,correlation, denom)\n",
    "    else:\n",
    "#     print('corr',correlation,'denom', denom)\n",
    "        correlation_length=sqrt(sq_corr_l)\n",
    "    end=time.time()-start\n",
    "    print('corre_length_end',end)\n",
    "    return correlation_length\n",
    "  \n",
    "\n",
    "    \n",
    "###############################################################################\n",
    "def percolation(im,p,size_sys,seed):\n",
    "    my_dpi=96 # DPI of the monitor\n",
    "\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "#     print('debut')\n",
    "\n",
    "    #create_directory('percolating')   #if we want to classify them inside each density directory\n",
    "    #create_directory('not_percolating')\n",
    "    \n",
    "    for t in range(im):\n",
    "        print('--- working in image', t, datetime.datetime.now())\n",
    "        start2=time.time()\n",
    "        lattice_para=lattice_config(size_sys,seed,p)\n",
    "\n",
    "        \n",
    "        occupied = lattice_para[0].nonzero()\n",
    "        n_clusters_pbc = 0\n",
    "        n_clusters = 0\n",
    "        cluster_pbc=np.zeros((size_sys,size_sys), dtype=int)-1\n",
    "        cluster=np.zeros((size_sys,size_sys), dtype=int)-1\n",
    "        sizes_pbc = Counter()\n",
    "        sizes = Counter()\n",
    "#         print('cluster')\n",
    "        print(\"Hoshen-Kopelman PBS START\", datetime.datetime.now())\n",
    "        for i, j in zip(*occupied):\n",
    "            if cluster_pbc[i,j] == -1:\n",
    "                cluster_matrix_pbc(i, j, n_clusters_pbc, size_sys,lattice_para[0],cluster_pbc, sizes_pbc)\n",
    "#                 cluster_matrix_pbc(i, j, n_clusters, size_sys,lattice,cluster, sizes)\n",
    "                n_clusters_pbc += 1\n",
    "        print(\"Hoshen-Kopelman PBC END\", datetime.datetime.now())\n",
    "        \n",
    "        print(\"Hoshen-Kopelman HW START\", datetime.datetime.now())\n",
    "        for i, j in zip(*occupied):\n",
    "            if cluster[i,j] == -1:\n",
    "                cluster_matrix(i, j, n_clusters, size_sys,lattice_para[0],cluster, sizes)\n",
    "#                 cluster_matrix_pbc(i, j, n_clusters, size_sys,lattice,cluster, sizes)\n",
    "                n_clusters += 1\n",
    "                #print(n_clusters)\n",
    "        print(\"Hoshen-Kopelman HW END\", datetime.datetime.now())\n",
    "        \n",
    "        print(\"PBC characterization\", datetime.datetime.now())\n",
    "            \n",
    "        order_pbc=OrderedDict(sizes_pbc.most_common())\n",
    "                  \n",
    "        classification_pbc=list(order_pbc)\n",
    "        #print(order)\n",
    "        \n",
    "        numbers_pbc = np.arange(0,n_clusters_pbc)\n",
    "        weight_pbc=-np.sort(-(numbers_pbc))\n",
    "        k_pbc=list(zip(classification_pbc,weight_pbc))\n",
    "        \n",
    "        correspondance_pbc=sorted(k_pbc, key = lambda t: t[0])\n",
    "        unzip_pbc=list(zip(*correspondance_pbc))\n",
    "        #print(unzip)\n",
    "        new_mapping_pbc=unzip_pbc[1]\n",
    "        \n",
    "        \n",
    "        print(\"HW characterization\", datetime.datetime.now())\n",
    "        \n",
    "        order=OrderedDict(sizes.most_common())\n",
    "                  \n",
    "        classification=list(order)\n",
    "        \n",
    "        \n",
    "        numbers = np.arange(0,n_clusters)\n",
    "        weight=-np.sort(-(numbers))\n",
    "        k=list(zip(classification,weight))\n",
    "        \n",
    "        correspondance=sorted(k, key = lambda t: t[0])\n",
    "        unzip=list(zip(*correspondance))\n",
    "        \n",
    "        new_mapping=unzip[1]\n",
    "\n",
    "        \n",
    "        \n",
    "        print(\"PBC coloring\", datetime.datetime.now())\n",
    "        \n",
    "        cluster_pbc_int= np.array([new_mapping_pbc[v]+1 \\\n",
    "                            if not v == -1 else 0 for v in cluster_pbc.flat]).reshape(size_sys,size_sys)\n",
    "        cluster_pbc_norm = np.array([(new_mapping_pbc[v]+1)/n_clusters_pbc \\\n",
    "                            if not v == -1 else 0 for v in cluster_pbc.flat]).reshape(size_sys,size_sys)\n",
    "        \n",
    "        \n",
    "        print(\"HW coloring\", datetime.datetime.now())\n",
    "        \n",
    "        cluster_int= np.array([new_mapping[v]+1 \\\n",
    "                            if not v == -1 else 0 for v in cluster.flat]).reshape(size_sys,size_sys)\n",
    "        cluster_norm = np.array([(new_mapping[v]+1)/n_clusters \\\n",
    "                            if not v == -1 else 0 for v in cluster.flat]).reshape(size_sys,size_sys)\n",
    "        cluster_nan = np.array([new_mapping[v]+1\\\n",
    "                           if not v == -1 else np.nan for v in cluster.flat]).reshape(size_sys,size_sys)\n",
    "\n",
    "        print(\"correlation calculations\", datetime.datetime.now())\n",
    "        \n",
    "        occ=len(list(zip(*cluster_int.nonzero())))\n",
    "        start4=time.time()\n",
    "        size_maxi=size_max(order_pbc,n_clusters)\n",
    "        proba_largest= (size_maxi[0]/(size_sys**2))**2\n",
    "        print('first correlation')\n",
    "        corr_value=correlation_function_pbc_new_diagonal(cluster_pbc_int,size_sys,n_clusters_pbc,seed)\n",
    "        print('end first correlation')\n",
    "        \n",
    "        square_proba=p*p\n",
    "        #size_max(order_pbc,n_clusters)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('proba largest', proba_largest,'\\n')\n",
    "        print('occ',occ,'\\n')\n",
    "        print('max_clus',size_maxi[0],'\\n')\n",
    "        print(cluster_pbc_int,'\\n')\n",
    "        #\n",
    "        \n",
    "        pl.plot(corr_value[0],corr_value[1],label='g(r) every clusters')\n",
    "        pl.plot(corr_value[2],corr_value[3], label='largest cluster')\n",
    "        pl.axhline(y=square_proba, color='g', linestyle='--')\n",
    "        pl.axhline(y=proba_largest, color='grey', linestyle='--')\n",
    "        pl.legend(loc='best')\n",
    "        pl.xlabel('distance r')\n",
    "        pl.ylabel('correlation function g(r)')\n",
    "        pl.title('Correlation function for system '+str(size_sys)+' at density '+str(p))\n",
    "        pl.savefig('pc_________s'+str(seed)+'corr_func_'+'__p'+str(p)+'_L'+str(size_sys)+'_s'+str(seed)+'_'+'.png')\n",
    "      \n",
    "    \n",
    "        corr_proba_largest=corr_value[1]-proba_largest\n",
    "        corr_value_zipped=list(zip(corr_value[0],corr_value[1], corr_proba_largest,corr_value[2],corr_value[3]))\n",
    "        \n",
    "    \n",
    "        header = '{0:^5s}   {1:^7s}   {2:^7s} {3:^5s}   {4:^7s} '.format('distance', 'Corr func','Corr func-proba largest','distance','Corr func largest')\n",
    "        filename='pc_________s'+str(seed)+'Correlation_function_2.txt'\n",
    "        np.savetxt(filename,corr_value_zipped, header=header, fmt=['    %.7f  ','    %.7f  ','    %.7f  ','  %.7f','  %.7f'])\n",
    "        \n",
    "        \n",
    "#         final_correlation_func_pbc_m_max=[x - proba_largest for x in final_correlation_func_pbc]\n",
    "\n",
    "        \n",
    "#         corr3=list(zip(distance_to_site_div_pbc,Correlation_func_div_pbc_max,final_correlation_func_pbc_m_max))\n",
    "#         header3 = '{0:^5s} {0:^1s}  {1:^7s}  '.format('distance','div', 'Correlation function - proba')\n",
    "#         filename3='pc_________s'+str(seed)+'Correlation_function_m_largest_proba_'+str(proba_largest)+'.txt'\n",
    "#         np.savetxt(filename3, corr3, header=header3, fmt=['    %.7f  ','    %.7f  ','  %.7f'])\n",
    "        \n",
    "#         pl.axhline(y=square_proba, color='g', linestyle='--')\n",
    "#         pl.plot(distance_to_site_pbc,final_correlation_func_pbc,label='g(r) every clusters')\n",
    "#         pl.plot(distance_to_site_pbc_max,final_correlation_func_pbc_max, label='g(r) largest cluster')\n",
    "#         pl.plot(distance_to_site_pbc,final_correlation_func_pbc_m_max, label='g(r) every cluster-proba to belong to largest cluster')\n",
    "#         pl.legend(loc='best')\n",
    "#         pl.xlabel('distance r')\n",
    "#         pl.ylabel('correlation function g(r)')\n",
    "#         pl.title('Correlation function for system '+str(size_sys)+' at density '+str(p))\n",
    "#         pl.savefig('pc_________s'+str(seed)+'corr_func_'+'__p'+str(p)+'_L'+str(size_sys)+'_s'+str(seed)+'_'+'.png')\n",
    "        \n",
    "#         pl.close()\n",
    "        \n",
    "#         pl.plot(distance_to_site_pbc,final_correlation_func_pbc,label='g(r) every clusters')\n",
    "#         pl.plot(distance_to_site_pbc_max,final_correlation_func_pbc_max, label='g(r) largest cluster')\n",
    "#         pl.plot(distance_to_site_pbc,final_correlation_func_pbc_m_max, label='g(r) every cluster-proba to belong to largest cluster')\n",
    "#         pl.legend(loc='best')\n",
    "#         pl.yscale('log')\n",
    "#         pl.xlabel('distance r')\n",
    "#         pl.ylabel('correlation function g(r)')\n",
    "#         pl.title('Correlation function for system '+str(size_sys)+' at density '+str(p))\n",
    "#         pl.savefig('pc_________s'+str(seed)+'log_corr_func_.png')\n",
    "    \n",
    "        \n",
    "        \n",
    "        end4=time.time()-start4\n",
    "        \n",
    "#         print('fin_corre', datetime.datetime.now())\n",
    "        \n",
    "        all_sizes = Counter(list(sizes.values()))\n",
    "        \n",
    "        #get size of largest cluster\n",
    "        if n_clusters !=0:\n",
    "            max_size = max(all_sizes.keys())\n",
    "            \n",
    "        if size_sys==100:\n",
    "            size_im=131\n",
    "        else:\n",
    "            size_im=size_sys+ (size_sys/100)*30\n",
    "       \n",
    "        fig =pl.figure(figsize=((size_im/my_dpi), (size_im/my_dpi)), dpi=my_dpi)\n",
    "        pl.axis('off')\n",
    "        pl.imshow(cluster_pbc_norm,cmap='Greys')\n",
    "#         print(cluster)\n",
    "#         print(cluster2)\n",
    "        occ=len(list(zip(*cluster_int.nonzero())))\n",
    "#         occ2=len(list(zip(*cluster2.nonzero())))\n",
    "#         print('occ1 bis',occ1_bis)\n",
    "#         print('occ2',occ2)\n",
    "        cmap2 = pl.cm.get_cmap('Greys')\n",
    "#         occupied=len(list(zip(*cluster1.nonzero())))\n",
    "       \n",
    "        top=set(x for x in cluster_nan[0][:]).intersection(set(y for y in cluster_nan[-1][:]))\n",
    "        side=set(w for w in cluster_nan[:,0]).intersection(set(z for z in cluster_nan[:,-1]))\n",
    "        \n",
    "        \n",
    "        HWTB=0\n",
    "        HWLR=0\n",
    "        PBCTB=0\n",
    "        PBCLR=0\n",
    "         \n",
    "        if (top!=set() or side!=set()):\n",
    "            #os.chdir('percolating') \n",
    "            union_top_side=top.union(side)\n",
    "            row1=cluster_nan[0][:]\n",
    "            cluster_pseudo_pbc=np.row_stack((cluster_nan,row1))\n",
    "            column1=cluster_pseudo_pbc[:,0]\n",
    "            cluster_pseudo_pbc=np.column_stack((cluster_pseudo_pbc,column1))\n",
    "            \n",
    "            top_pbc=set(x for x in cluster_pseudo_pbc[0][:]).intersection(set(y for y in cluster_pseudo_pbc[-1][:]))\n",
    "            side_pbc=set(w for w in cluster_pseudo_pbc[:,0]).intersection(set(z for z in cluster_pseudo_pbc[:,-1]))\n",
    "            \n",
    "            union_top_side_spanning_pbc= side_pbc.union(top_pbc)\n",
    "            \n",
    "            \n",
    "            if (union_top_side_spanning_pbc!=set() and union_top_side_spanning_pbc.intersection(union_top_side)!=set):\n",
    "                size_side_spanning_pbc=0\n",
    "                size_top_spanning_pbc=0\n",
    "                size_top_side_spanning=0\n",
    "                \n",
    "                if side_pbc!=set() and top_pbc!=set():                    \n",
    "                    size_span_clus=size_spanning_cluster(union_top_side_spanning_pbc,cluster_pseudo_pbc,cluster_pbc_int)\n",
    "                    size_top_side_spanning=size_span_clus\n",
    "                    \n",
    "                    rgba1=cmap2(next(iter(top_pbc)))\n",
    "                    proba_span=(size_top_side_spanning/(size_sys*size_sys))\n",
    "                    \n",
    "                    PBCTB=1\n",
    "                    PBCLR=1\n",
    "                \n",
    "                elif side_pbc!=set():\n",
    "                    size_span_clus=size_spanning_cluster(side_pbc,cluster_pseudo_pbc,cluster_pbc_int)\n",
    "                    size_side_spanning_pbc= size_span_clus\n",
    "                    rgba2_pbc=cmap2(next(iter(side_pbc)))  #rgb color tuple + alpha\n",
    "                    proba_span=(size_side_spanning/(size_sys*size_sys))**2\n",
    "                    PBCLR=1\n",
    "                 \n",
    "                else:\n",
    "                    size_span_clus=size_spanning_cluster(top_pbc,cluster_pseudo_pbc,cluster_pbc_int)\n",
    "                    size_top_spanning_pbc=size_span_clus\n",
    "                    rgba1_pbc=cmap2(next(iter(top_pbc)))\n",
    "                    proba_span=(size_top_spanning/(size_sys*size_sys))\n",
    "                    PBCTB=1\n",
    "                \n",
    "#                 mapping = dict(zip(cluster_nan.flat,cluster_pbc_int.flat))\n",
    "#                 keys_mapping=mapping.keys()\n",
    "#                 values_mapping=mapping.values()\n",
    "                \n",
    "                \n",
    "#                 cluster=[]\n",
    "#                 for i in:\n",
    "#                     if l[i]==n:\n",
    "#                         cluster.append(p[i])\n",
    "#                         print(cluster)\n",
    "    \n",
    "             \n",
    "\n",
    "           \n",
    "#             color_point(cluster_int,top,side)  #,center_b=0,quarter_b=0,three_quarter_b=0,anti_quarter_b=0,anti_three_quarter_b=0)\n",
    "            correlation_len=correlation_l(corr_value[0],corr_value[1], size_sys,proba_span,proba_largest,p) \n",
    "           \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            size_side_spanning=0\n",
    "            size_top_spanning=0\n",
    "            rgba1=0\n",
    "            rgba2=0\n",
    "            \n",
    "            if side!=set() and top!=set():\n",
    "                size_span_clus_side=size_spanning_cluster(side,cluster_norm,cluster_pbc_int)\n",
    "#                 size_side_spanning= size_spanning\n",
    "                rgba2_pbc=cmap2(next(iter(side)))\n",
    "                size_span_clus_top=size_spanning_cluster(top,cluster_norm,cluster_pbc_int)\n",
    "                #size_top_spanning=size_spanning\n",
    "                rgba1_pbc=cmap2(next(iter(top)))\n",
    "                HWTB=1\n",
    "                HWLR=1\n",
    "                \n",
    "            elif side!=set():\n",
    "                size_span_clus_side=size_spanning_cluster(side,cluster_norm,cluster_pbc_int)\n",
    "#                 size_side_spanning= size_spanning\n",
    "                rgba2_pbc=cmap2(next(iter(side)))  #rgb color tuple + alpha\n",
    "                HWLR=1\n",
    "                 \n",
    "            else:\n",
    "                size_span_clus_top=size_spanning_cluster(top,cluster_norm,cluster_pbc_int)\n",
    "#                 size_top_spanning=size_spanning\n",
    "                rgba1_pbc=cmap2(next(iter(top)))\n",
    "                HWTB=1\n",
    "                \n",
    "                \n",
    "                \n",
    "            filename1='pc_1_'+str(HWTB)+'_'+str(HWLR)+'_'+str(PBCTB)+'_'+str(PBCLR)+'__p'+str(p)+'_L'+str(size_sys)+'_s'+str(seed)+\\\n",
    "                        '_top_'+str(top)+'_side_'+str(side)+'_size_max_clus'+str(max_size)+\\\n",
    "                        '_occ_'+str(occ)+'_'\n",
    "                       \n",
    "            \n",
    "            fig.savefig(filename1+'.png',bbox_inches='tight', pad_inches = 0,dpi=my_dpi)\n",
    "            \n",
    "#             filename='pc_________s'+str(seed)+'correlation'\n",
    "            z=open(filename1+'corr_length'+'.txt', \"w+\")\n",
    "            z.write('\\n'+repr(correlation_len)+'\\n')\n",
    "            z.close()\n",
    "                \n",
    "                \n",
    "#             f=open(filename1+'.txt', \"w+\")\n",
    "#             f.write('Total number of cluster= '+ repr(n_clusters)+'\\n')\n",
    "#             f.write('Size of the largest cluster (number of site occupied)= '+ repr(max_size)+'\\n')\n",
    "#             f.write('Number of clusters with given size= ' +repr(sizes)+\"\\n\")\n",
    "#             f.write('Spanning cluster top-bottom = '+ repr(top)+' = '+repr(size_top_spanning)+\"\\n\")\n",
    "#             f.write('Spanning cluster side-side= '+ repr(side)+ ' = '+repr(size_side_spanning)+\"\\n\")\n",
    "#             f.write('color of the spanning cluster = '+repr(rgba1)+\"\\n\")\n",
    "#             f.write('color of the spanning cluster = '+repr(rgba2)+\"\\n\")\n",
    "#             f.close()\n",
    "            \n",
    "            \n",
    "\n",
    "      \n",
    "#             h= open(filename1+'.pkl', \"wb\")\n",
    "#             pickle.dump(cluster1,h)\n",
    "#             h.close()\n",
    "            \n",
    "            #os.chdir('..')\n",
    "        else:\n",
    "            size_max(order_pbc,n_clusters)\n",
    "            #proba_max=(max_clus/(size_sys*size_sys))**2\n",
    "            correlation_len=correlation_l(corr_value[0],corr_value[1], size_sys,proba_largest,proba_largest,p)\n",
    "            \n",
    "            #os.chdir('not_percolating')\n",
    "            filename0='pc_0_'+str(HWTB)+'_'+str(HWLR)+'_'+str(PBCTB)+'_'+str(PBCLR)+'__p'+str(p)+'_L'+str(size_sys)+'_s'+str(seed)+\\\n",
    "                        '_size_max_clus'+str(max_clus)+'_n'+str(max_n_clus)+'_occ_'+str(occ)+'_'\n",
    "            \n",
    "            fig.savefig(filename0+'_.png', bbox_inches='tight',\\\n",
    "                        pad_inches = 0,dpi=my_dpi)\n",
    "            \n",
    "            #filename='pc_________s'+str(seed)+'correlation'\n",
    "            z=open(filename0+'corr_length'+'.txt', \"w+\")\n",
    "            z.write('\\n'+repr(correlation_len)+'\\n')\n",
    "            z.close()\n",
    "            \n",
    "            \n",
    "#             print(cluster_norm)\n",
    "            \n",
    "            \n",
    "#             g=open(filename0+'.txt', \"w+\")\n",
    "#             g.write('Total number of cluster= '+ repr(n_clusters)+'\\n')\n",
    "#             g.write('Size of the largest cluster (number of site occupied)= '+ repr(max_size)+'\\n')\n",
    "#             g.write('Sizes of each clusters (number associated to the cluster: number of occupied sites)= ' +repr(sizes)+\"\\n\")\n",
    "#             g.close()\n",
    "            \n",
    "#             i=open(filename0+'.pkl', \"wb\")\n",
    "#             pickle.dump(cluster1,i)\n",
    "#             i.close()\n",
    "            #os.chdir('..')\n",
    "\n",
    "        pl.close('all')\n",
    "        seed+=1\n",
    "        end2=time.time()-start2\n",
    "        print(end2)\n",
    "\n",
    "    return cluster,n_clusters,cluster_pbc,n_clusters_pbc, sizes_pbc,lattice,new_mapping,order,order_pbc,occ,\\\n",
    "sizes,cluster_int, top,side,cluster_nan,\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "def percolation_density(number_configs,perco_list,lattice_size,seed):\n",
    "    global correlation, correlation_func\n",
    "    import os\n",
    "    #create_directory('L'+str(L))\n",
    "    #os.chdir('L'+str(L))\n",
    "    import time\n",
    "    correlation=[]\n",
    "    correlation_func=[]\n",
    "    dens=[]\n",
    "    start1= time.time()\n",
    "    seed_ini=seed\n",
    "    im_ini=number_configs\n",
    "    for p in perco_list:\n",
    "        new_im=0\n",
    "        seed=seed_ini\n",
    "        im=im_ini\n",
    "        \n",
    "        if os.path.exists('p'+str(p)) and len(os.listdir('p'+str(p)))!=0:\n",
    "            print('A directory '+'p='+str(p)+' already exists')\n",
    "            #print (\"Creation of the directory failed\")\n",
    "            check_name('p'+str(p))\n",
    "            print('A file already exist with max seed=',max_seed)\n",
    "            os.chdir('p'+str(p))\n",
    "            if im>= nbre_images:\n",
    "                im=im-nbre_images\n",
    "                while im > 0:\n",
    "                    if seed in seed_list:\n",
    "                        print('Image with seed = ',seed, 'already exists')\n",
    "                        seed+=1\n",
    "                    else:\n",
    "                        dens.append(p)\n",
    "                        percolation(1,p,lattice_size,seed) \n",
    "                        correlation.append(correlation_length)\n",
    "#                         correlation_func.append(mean_int_func)\n",
    "#                        im-=1\n",
    "                        new_im+=1\n",
    "                        seed+=1\n",
    "                        print('NEW image with seed = ',seed, 'was created')\n",
    "            else:\n",
    "                print('The directory already contains ', nbre_images,\\\n",
    "                      ' images, please choose a higher number of configurations.')\n",
    "                    \n",
    "            os.chdir('..')\n",
    "            if new_im!=0:\n",
    "                print(\"-->\",new_im, 'new images were created')\n",
    "        \n",
    "        else:\n",
    "            create_directory('p'+str(p)+'new_diagonal')\n",
    "            os.chdir('p'+str(p)+'new_diagonal')\n",
    "            percolation(im,p,lattice_size,seed_ini)\n",
    "            os.chdir('..')\n",
    "            print(im, 'new images were created')\n",
    "#     os.chdir('..')  \n",
    "    end1=time.time()\n",
    "    total_time=end1-start1\n",
    "    print(\"Images generated in : \", total_time, \"seconds\")\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('every_sites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perco_list=[val/10000 for val in range(1000,10000,1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/physics/phrhmb/Desktop/test_5_01_21/every_sites'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "percolation_density(1,perco_list,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
