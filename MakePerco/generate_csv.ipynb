{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file='/storage/disqs/ML-Percolation/Data/L100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_c=[d.name for d in os.scandir(csv_file) if d.is_dir()]\n",
    "float(re.findall(regex2,directory_c[4])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.555 0.565 0.575 0.585 0.595 0.605 0.615 0.625 0.635 0.645 0.655]\n",
      "###################\n",
      "['p0.655', 'p0.4', 'p0.62', 'p0.57', 'p0.65', 'p0.3', 'p0.9', 'p0.625', 'p0.555', 'p0.7', 'p0.61', 'p0.645', 'p0.59', 'p0.635', 'p0.66', 'p0.8', 'p0.2', 'p0.595', 'p0.605', 'p0.56', 'p0.64', 'p0.63', 'p0.5', 'p0.565', 'p0.1', 'p0.615', 'p0.585', 'p0.55', 'p0.575', 'p0.58', 'p0.6']\n",
      "###################\n",
      "['p0.4', 'p0.62', 'p0.57', 'p0.65', 'p0.3', 'p0.9', 'p0.7', 'p0.61', 'p0.59', 'p0.66', 'p0.8', 'p0.2', 'p0.56', 'p0.64', 'p0.63', 'p0.5', 'p0.1', 'p0.55', 'p0.58', 'p0.6']\n"
     ]
    }
   ],
   "source": [
    "regex2 = re.compile('\\d+\\.\\d+')\n",
    "rejected=np.round(np.arange(0.555, 0.665, 0.010).astype(float),3)\n",
    "#rejected=#[0.555,0.565,0.575,0.585 ,0.595,0.605,0.615,0.625,0.635,0.645,0.655]\n",
    "print(rejected)\n",
    "print('###################')\n",
    "directory_c=[d.name for d in os.scandir(csv_file) if d.is_dir()]\n",
    "print(directory_c)\n",
    "print('###################')\n",
    "directory=[d.name for d in os.scandir(csv_file) if d.is_dir() if not float(re.findall(regex2,d.name)[0]) in rejected]\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv_pkl_slice_true_c(data_dir,n_to_keep,data_type=None):    \n",
    "    regex2 = re.compile('\\d+\\.\\d+')\n",
    "    if data_type=='h_res':\n",
    "\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        filename='_h_res.csv'\n",
    "    elif data_type=='very_h_res':\n",
    "        \n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.62]    \n",
    "        filename='_55_62.csv'\n",
    "    elif data_type=='andreas':\n",
    "        \n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.56<=float(re.findall(regex2,d.name)[0])<=0.605]\n",
    "    \n",
    "        filename='_56_605.csv'\n",
    "    elif data_type=='test':\n",
    "       \n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.50<=float(re.findall(regex2,d.name)[0])<=0.70]\n",
    "    \n",
    "        filename='_50_70.csv'\n",
    "    elif data_type=='reg':\n",
    "        \n",
    "        rejected=np.round(np.arange(0.555, 0.665, 0.010).astype(float),3)\n",
    "        print(rejected)\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not float(re.findall(regex2,d.name)[0]) in rejected]\n",
    "        filename='_reg_train_1_over_2.csv'\n",
    "    \n",
    "    elif data_type=='int':\n",
    "        \n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        directory.append('p0.6')\n",
    "        filename='_int.csv'\n",
    "        \n",
    "    elif data_type=='int_':\n",
    "        \n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.5<float(re.findall(regex2,d.name)[0])]    \n",
    "        filename='_int_0.5.csv'\n",
    "    elif data_type=='h_res_plus':\n",
    "        \n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]\n",
    "        directory.append('p0.5')\n",
    "        directory.append('p0.7')\n",
    "        filename='_h_res_plus.csv'\n",
    "    elif data_type=='vhres':\n",
    "        \n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<0.61]\n",
    "        filename='_vhres.csv'\n",
    "    elif data_type=='1_over_2':\n",
    "        temp_directory=[d.name for d in os.scandir(data_dir) if d.is_dir()]\n",
    "        temp_directory.sort()\n",
    "        directory=temp_directory[0::2]\n",
    "        print(directory)\n",
    "        filename='_1_over_2.csv'\n",
    "    else:\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir()]\n",
    "        filename='.csv'\n",
    "\n",
    "\n",
    "    \n",
    "    regex1= re.compile('\\d+')\n",
    "    for p in directory:\n",
    "        filename_avg_c= data_dir+'/'+p+'/avg_corrlen_L100_'+p+'.acl'\n",
    "        corr=np.loadtxt(filename_avg_c)\n",
    "        \n",
    "        list_files=os.listdir(data_dir+'/'+p)\n",
    "        \n",
    "        \n",
    "        print(data_dir+'/'+p)\n",
    "        print(corr)\n",
    "        if corr.size > 0:\n",
    "            corr=float(corr)\n",
    "       \n",
    "        \n",
    "        list_pkl = [a for a in list_files if \".pkl\" in a]\n",
    "        n_to_del= len(list_pkl) - n_to_keep\n",
    "        new_list_pkl= list(random.sample(list_pkl, n_to_keep))  \n",
    "          \n",
    "        print('origine list',len(list_pkl),'new list', len(new_list_pkl))\n",
    "        len_pkl=len(new_list_pkl)\n",
    "        data_corr=np.loadtxt(data_dir+'/'+p+'/corlen_L100_'+p+'.cl',unpack=True)\n",
    "        seeds=data_corr[0]\n",
    "        corr_l_list=data_corr[2]\n",
    "        \n",
    "        \n",
    "#         result = np.where(data[0] == 1000446293)\n",
    "\n",
    "        #str(HWTB)+'_'+str(HWLR)+'_'+str(PBCTB)+'_'+str(PBCLR)\n",
    "        \n",
    "        for file_pkl in range(len_pkl):\n",
    "            filename_pkl=new_list_pkl[file_pkl]\n",
    "            #print(new_list_pkl[file_pkl])\n",
    "            \n",
    "            seed=filename_pkl.split('_')[9]       \n",
    "            regex3 = re.compile('\\d+')\n",
    "            seed_reg=re.findall(regex3,seed)\n",
    "            seed_number=int(seed_reg[0])\n",
    "           \n",
    "            #print('seed number',seed_number)\n",
    "            array_index_seed = np.where(seeds == seed_number)\n",
    "            #print('array',array_index_seed)\n",
    "            index_seed=int(array_index_seed[0])\n",
    "            corr_l=corr_l_list[index_seed]\n",
    "           \n",
    "            \n",
    "            span_0=filename_pkl.split('_')[1]                  \n",
    "            span_reg_0=re.findall(regex1,span_0)\n",
    "            span_pkl=int(span_reg_0[0])\n",
    "            \n",
    "            span_hwtb=filename_pkl.split('_')[2]                  \n",
    "            span_reg_hwtb=re.findall(regex1,span_hwtb)\n",
    "            span_hwtb_pkl=int(span_reg_hwtb[0])\n",
    "            \n",
    "            span_hwlr=filename_pkl.split('_')[3]                  \n",
    "            span_reg_hwlr=re.findall(regex1,span_hwlr)\n",
    "            span_hwlr_pkl=int(span_reg_hwlr[0])\n",
    "            \n",
    "            span_pbctb=filename_pkl.split('_')[4]                  \n",
    "            span_reg_pbctb=re.findall(regex1,span_pbctb)\n",
    "            span_pbctb_pkl=int(span_reg_pbctb[0])\n",
    "            \n",
    "            span_pbclr=filename_pkl.split('_')[5]                  \n",
    "            span_reg_pbclr=re.findall(regex1,span_pbclr)\n",
    "            span_pbclr_pkl=int(span_reg_pbclr[0])\n",
    "            data_pkl=[filename_pkl,p,span_pkl,span_hwtb_pkl,span_hwlr_pkl,span_pbctb_pkl,span_pbclr_pkl,corr_l,corr] \n",
    "            \n",
    "            if 'data_pkl_100_'+str(n_to_keep)+filename in os.listdir('.'):\n",
    "                with open('data_pkl_100_'+str(n_to_keep)+filename, 'a', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "            else:\n",
    "                with open('data_pkl_100_'+str(n_to_keep)+filename, 'w', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "        \n",
    "        \n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p0.1', 'p0.3', 'p0.5', 'p0.555', 'p0.565', 'p0.575', 'p0.585', 'p0.595', 'p0.605', 'p0.615', 'p0.625', 'p0.635', 'p0.645', 'p0.655', 'p0.7', 'p0.9']\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.1\n",
      "0.17628146461648167\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.3\n",
      "0.6447076714375688\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.5\n",
      "3.3614456064157623\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.555\n",
      "6.225063469993829\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.565\n",
      "6.601050669498028\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.575\n",
      "6.528071888035779\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.585\n",
      "5.6149671695433625\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.595\n",
      "4.1924325476811335\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.605\n",
      "2.966226013893822\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.615\n",
      "2.0946830906621634\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.625\n",
      "1.527460851700905\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.635\n",
      "1.1535874497407623\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.645\n",
      "0.8828818381301329\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.655\n",
      "0.6926886486308412\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.7\n",
      "0.2792705894723602\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.9\n",
      "0.05447152741639959\n",
      "origine list 10000 new list 10000\n"
     ]
    }
   ],
   "source": [
    "generate_csv_pkl_slice_true_c(csv_file,10000,'1_over_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/disqs/ML-Percolation/Data/L100/p0.655\n",
      "0.6926886486308412\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.4\n",
      "1.2976423586484553\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.62\n",
      "1.783867182462122\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.57\n",
      "6.659478252369829\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.65\n",
      "0.7820451583210781\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.3\n",
      "0.6447076714375688\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.9\n",
      "0.05447152741639959\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.625\n",
      "1.527460851700905\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.555\n",
      "6.225063469993829\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.7\n",
      "0.2792705894723602\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.61\n",
      "2.487681905165067\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.645\n",
      "0.8828818381301329\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.59\n",
      "4.948428195531288\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.635\n",
      "1.1535874497407623\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.66\n",
      "0.6222662487800603\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.8\n",
      "0.07999742452113419\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.2\n",
      "0.3489107033582161\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.595\n",
      "4.1924325476811335\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.605\n",
      "2.966226013893822\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.56\n",
      "6.464405555272026\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.64\n",
      "1.001719674510553\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.63\n",
      "1.3339250701559493\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.5\n",
      "3.3614456064157623\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.565\n",
      "6.601050669498028\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.1\n",
      "0.17628146461648167\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.615\n",
      "2.0946830906621634\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.585\n",
      "5.6149671695433625\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.55\n",
      "5.927615392897483\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.575\n",
      "6.528071888035779\n",
      "origine list 10000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.58\n",
      "6.169084490210236\n",
      "origine list 50000 new list 10000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.6\n",
      "3.548754809084376\n",
      "origine list 10000 new list 10000\n"
     ]
    }
   ],
   "source": [
    "generate_csv_pkl_slice_true_c(csv_file,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/disqs/ML-Percolation/Data/L100/p0.655\n",
      "0.6926886486308412\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.4\n",
      "1.2976423586484553\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.62\n",
      "1.783867182462122\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.57\n",
      "6.659478252369829\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.65\n",
      "0.7820451583210781\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.3\n",
      "0.6447076714375688\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.9\n",
      "0.05447152741639959\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.625\n",
      "1.527460851700905\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.555\n",
      "6.225063469993829\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.7\n",
      "0.2792705894723602\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.61\n",
      "2.487681905165067\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.645\n",
      "0.8828818381301329\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.59\n",
      "4.948428195531288\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.635\n",
      "1.1535874497407623\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.66\n",
      "0.6222662487800603\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.8\n",
      "0.07999742452113419\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.2\n",
      "0.3489107033582161\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.595\n",
      "4.1924325476811335\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.605\n",
      "2.966226013893822\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.56\n",
      "6.464405555272026\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.64\n",
      "1.001719674510553\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.63\n",
      "1.3339250701559493\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.5\n",
      "3.3614456064157623\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.565\n",
      "6.601050669498028\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.1\n",
      "0.17628146461648167\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.615\n",
      "2.0946830906621634\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.585\n",
      "5.6149671695433625\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.55\n",
      "5.927615392897483\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.575\n",
      "6.528071888035779\n",
      "origine list 10000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.58\n",
      "6.169084490210236\n",
      "origine list 50000 new list 5000\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.6\n",
      "3.548754809084376\n",
      "origine list 10000 new list 5000\n"
     ]
    }
   ],
   "source": [
    "generate_csv_pkl_slice_true_c(csv_file,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv_pkl_no_c(main_dir,to_keep,size,data_type=None):\n",
    "    data_dir=main_dir#+'/Line/L'+str(size)\n",
    "    #os.chdir(data_dir)\n",
    "    #print(os.listdir(data_dir))\n",
    "    if data_type=='h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        filename='_h_res.csv'\n",
    "    elif data_type=='very_h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.62]    \n",
    "        filename='_55_62.csv'\n",
    "    elif data_type=='andreas':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.56<=float(re.findall(regex2,d.name)[0])<=0.605]\n",
    "    \n",
    "        filename='_56_605.csv'\n",
    "    elif data_type=='int':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        directory.append('p0.6')\n",
    "        filename='_int.csv'\n",
    "        \n",
    "    elif data_type=='int_':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.5<float(re.findall(regex2,d.name)[0])]    \n",
    "        filename='_int_0.5.csv'\n",
    "    elif data_type=='h_res_plus':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]\n",
    "        directory.append('p0.5')\n",
    "        directory.append('p0.7')\n",
    "        filename='_h_res_plus.csv'\n",
    "    elif data_type=='all_span':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.7<=float(re.findall(regex2,d.name)[0])]\n",
    "    \n",
    "        filename='_all_span_70_90.csv'\n",
    "    else:\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir()]\n",
    "        filename='.csv'\n",
    "\n",
    "    #print(directory)\n",
    "    \n",
    "    regex1= re.compile('\\d+')\n",
    "    for p in directory:\n",
    "#         filename_avg_c= data_dir+'/'+p+'/avg_corrlen_L100_'+p+'.acl'\n",
    "#         corr=np.loadtxt(filename_avg_c)\n",
    "        \n",
    "        list_files=os.listdir(data_dir+'/'+p)\n",
    "        \n",
    "        \n",
    "        print(data_dir+'/'+p)\n",
    "#         print(corr)\n",
    "#         if corr.size > 0:\n",
    "#             corr=float(corr)\n",
    "       \n",
    "        \n",
    "        list_pkl = [a for a in list_files if \".pkl\" in a]\n",
    "        #n_to_del = len(list_pkl) - to_keep\n",
    "        #new_list_pkl = list(random.sample(list_pkl, to_keep))  \n",
    "        #new_list_pkl = [file for file in list_pkl if file in temp]  \n",
    "        #print('origine list',len(list_pkl),'new list', len(new_list_pkl))\n",
    "        #new_list_pkl=list_pkl\n",
    "        #len_pkl=len(new_list_pkl)\n",
    "       \n",
    "        len_pkl=len(list_pkl)\n",
    "        print('origine list',len(list_pkl))\n",
    "#         data_corr=np.loadtxt(data_dir+'/'+p+'/corlen_L100_'+p+'.cl',unpack=True)\n",
    "        #seeds=data_corr[0]\n",
    "#         corr_l_list=data_corr[2]\n",
    "        \n",
    "        \n",
    "#         result = np.where(data[0] == 1000446293)\n",
    "\n",
    "        #str(HWTB)+'_'+str(HWLR)+'_'+str(PBCTB)+'_'+str(PBCLR)\n",
    "        \n",
    "        for file_pkl in range(len_pkl):\n",
    "            filename_pkl=list_pkl[file_pkl]\n",
    "            \n",
    "            seed=filename_pkl.split('_')[9]       \n",
    "            regex3 = re.compile('\\d+')\n",
    "            seed_reg=re.findall(regex3,seed)\n",
    "            seed_number=int(seed_reg[0])\n",
    "           \n",
    "            #print(seed_number)\n",
    "#             array_index_seed = np.where(seeds == seed_number)\n",
    "#             #print(array_index_seed)\n",
    "#             index_seed=int(array_index_seed[0])\n",
    "#             corr_l=corr_l_list[index_seed]\n",
    "           \n",
    "            \n",
    "            span_0=filename_pkl.split('_')[1]                  \n",
    "            span_reg_0=re.findall(regex1,span_0)\n",
    "            span_pkl=int(span_reg_0[0])\n",
    "            \n",
    "            span_hwtb=filename_pkl.split('_')[2]                  \n",
    "            span_reg_hwtb=re.findall(regex1,span_hwtb)\n",
    "            span_hwtb_pkl=int(span_reg_hwtb[0])\n",
    "            \n",
    "            span_hwlr=filename_pkl.split('_')[3]                  \n",
    "            span_reg_hwlr=re.findall(regex1,span_hwlr)\n",
    "            span_hwlr_pkl=int(span_reg_hwlr[0])\n",
    "            \n",
    "            span_pbctb=filename_pkl.split('_')[4]                  \n",
    "            span_reg_pbctb=re.findall(regex1,span_pbctb)\n",
    "            span_pbctb_pkl=int(span_reg_pbctb[0])\n",
    "            \n",
    "            span_pbclr=filename_pkl.split('_')[5]                  \n",
    "            span_reg_pbclr=re.findall(regex1,span_pbclr)\n",
    "            span_pbclr_pkl=int(span_reg_pbclr[0])\n",
    "            data_pkl=[filename_pkl,p,span_pkl,span_hwtb_pkl,span_hwlr_pkl,span_pbctb_pkl,span_pbclr_pkl]#,corr_l,corr] \n",
    "            \n",
    "            #print(os.getcwd())\n",
    "            if 'data_pkl_'+str(size)+'_test_RandomPath_'+str(to_keep)+filename in os.listdir('.'):\n",
    "                with open('data_pkl_'+str(size)+'_test_RandomPath_'+str(to_keep)+filename, 'a', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "            else:\n",
    "                with open('data_pkl_'+str(size)+'_test_RandomPath_'+str(to_keep)+filename, 'w', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "        \n",
    "        \n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.64\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.56\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.575\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.7\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.63\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.615\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.585\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.565\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.55\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.595\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.605\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.58\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.62\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.635\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.6\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.1\n",
      "origine list 1\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.645\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.65\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.555\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.57\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.59\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.625\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.61\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.5\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.2\n",
      "origine list 1\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.66\n",
      "origine list 1000\n",
      "/storage/disqs/ML-Percolation/Data/RandomPath/L100/p0.655\n",
      "origine list 1000\n"
     ]
    }
   ],
   "source": [
    "generate_csv_pkl_no_c(csv_file,1000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/disqs/ML-Percolation/Data/L100/p0.4\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.3\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.9\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.7\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.8\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.2\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.5\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.1\n",
      "/storage/disqs/ML-Percolation/Data/L100/p0.6\n"
     ]
    }
   ],
   "source": [
    "generate_csv_pkl_no_c(csv_file,5000,100,data_type='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv_pkl_no_c_p(data_dir,to_keep,data_type=None):    \n",
    "    \n",
    "    if data_type=='h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        filename='_h_res.csv'\n",
    "    elif data_type=='very_h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.62]    \n",
    "        filename='_55_62.csv'\n",
    "    \n",
    "    elif data_type=='int':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        directory.append('p0.6')\n",
    "        filename='_int.csv'\n",
    "        \n",
    "    elif data_type=='int_':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.5<float(re.findall(regex2,d.name)[0])]    \n",
    "        filename='_int_0.5.csv'\n",
    "    elif data_type=='h_res_plus':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]\n",
    "        directory.append('p0.5')\n",
    "        directory.append('p0.7')\n",
    "        filename='_h_res_plus.csv'\n",
    "    elif data_type=='all_span':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.7<=float(re.findall(regex2,d.name)[0])<=0.66]\n",
    "    \n",
    "        filename='_all_span.csv'\n",
    "    elif data_type=='andreas':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.56<=float(re.findall(regex2,d.name)[0])<=0.61]\n",
    "    \n",
    "        filename='_56_61.csv'\n",
    "    else:\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir()]\n",
    "        filename='.csv'\n",
    "\n",
    "\n",
    "    \n",
    "    regex1= re.compile('\\d+')\n",
    "    for p in directory:\n",
    "#         filename_avg_c= data_dir+'/'+p+'/avg_corrlen_L100_'+p+'.acl'\n",
    "#         corr=np.loadtxt(filename_avg_c)\n",
    "        \n",
    "        list_files=os.listdir(data_dir+'/'+p)\n",
    "        \n",
    "        \n",
    "        print(data_dir+'/'+p)\n",
    "#         print(corr)\n",
    "#         if corr.size > 0:\n",
    "#             corr=float(corr)\n",
    "       \n",
    "        \n",
    "        list_pkl = [a for a in list_files if \".pkl\" in a]\n",
    "        n_to_del = len(list_pkl) - to_keep\n",
    "        temp = set(random.sample(list_pkl, to_keep))  \n",
    "        new_list_pkl = [file for file in list_pkl if file in temp]  \n",
    "        print('origine list',len(list_pkl),'new list', len(new_list_pkl))\n",
    "        len_pkl=len(new_list_pkl)\n",
    "#         data_corr=np.loadtxt(data_dir+'/'+p+'/corlen_L100_'+p+'.cl',unpack=True)\n",
    "        #seeds=data_corr[0]\n",
    "#         corr_l_list=data_corr[2]\n",
    "        \n",
    "        \n",
    "#         result = np.where(data[0] == 1000446293)\n",
    "\n",
    "        #str(HWTB)+'_'+str(HWLR)+'_'+str(PBCTB)+'_'+str(PBCLR)\n",
    "        \n",
    "        for file_pkl in range(len_pkl):\n",
    "            filename_pkl=new_list_pkl[file_pkl]\n",
    "            \n",
    "            seed=filename_pkl.split('_')[9]       \n",
    "            regex3 = re.compile('\\d+')\n",
    "            seed_reg=re.findall(regex3,seed)\n",
    "            seed_number=int(seed_reg[0])\n",
    "           \n",
    "            #print(seed_number)\n",
    "#             array_index_seed = np.where(seeds == seed_number)\n",
    "#             #print(array_index_seed)\n",
    "#             index_seed=int(array_index_seed[0])\n",
    "#             corr_l=corr_l_list[index_seed]\n",
    "           \n",
    "            \n",
    "            span_0=filename_pkl.split('_')[1]                  \n",
    "            span_reg_0=re.findall(regex1,span_0)\n",
    "            span_pkl=int(span_reg_0[0])\n",
    "            \n",
    "            span_hwtb=filename_pkl.split('_')[2]                  \n",
    "            span_reg_hwtb=re.findall(regex1,span_hwtb)\n",
    "            span_hwtb_pkl=int(span_reg_hwtb[0])\n",
    "            \n",
    "            span_hwlr=filename_pkl.split('_')[3]                  \n",
    "            span_reg_hwlr=re.findall(regex1,span_hwlr)\n",
    "            span_hwlr_pkl=int(span_reg_hwlr[0])\n",
    "            \n",
    "            span_pbctb=filename_pkl.split('_')[4]                  \n",
    "            span_reg_pbctb=re.findall(regex1,span_pbctb)\n",
    "            span_pbctb_pkl=int(span_reg_pbctb[0])\n",
    "            \n",
    "            span_pbclr=filename_pkl.split('_')[5]                  \n",
    "            span_reg_pbclr=re.findall(regex1,span_pbclr)\n",
    "            span_pbclr_pkl=int(span_reg_pbclr[0])\n",
    "            data_pkl=[filename_pkl,p,span_pkl,span_hwtb_pkl,span_hwlr_pkl,span_pbctb_pkl,span_pbclr_pkl]#,corr_l,corr] \n",
    "            \n",
    "            if 'data_pkl_'+str(p)+'_10_'+str(to_keep)+filename in os.listdir('.'):\n",
    "                with open('data_pkl_'+str(p)+'_10_'+str(to_keep)+filename, 'a', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "            else:\n",
    "                with open('data_pkl_'+str(p)+'_10_'+str(to_keep)+filename, 'w', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "        \n",
    "        \n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_csv_pkl_no_c_p(csv_file,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_csv_pkl_no_c_p(csv_file,5000,data_type='andreas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv_pkl_no_c_p_crosses(data_dir,n_to_del,data_type=None):    \n",
    "    data_folder=data_dir.split('/')[-1] \n",
    "    if data_type=='h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        filename='_h_res.csv'\n",
    "    elif data_type=='very_h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.62]    \n",
    "        filename='_55_62.csv'\n",
    "    \n",
    "    elif data_type=='int':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        directory.append('p0.6')\n",
    "        filename='_int.csv'\n",
    "        \n",
    "    elif data_type=='int_':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.5<float(re.findall(regex2,d.name)[0])]    \n",
    "        filename='_int_0.5.csv'\n",
    "    elif data_type=='h_res_plus':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]\n",
    "        directory.append('p0.5')\n",
    "        directory.append('p0.7')\n",
    "        filename='_h_res_plus.csv'\n",
    "    elif data_type=='all_span':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.7<=float(re.findall(regex2,d.name)[0])<=0.66]\n",
    "    \n",
    "        filename='_all_span.csv'\n",
    "    elif data_type=='andreas':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.56<=float(re.findall(regex2,d.name)[0])<=0.61]\n",
    "    \n",
    "        filename='_56_61.csv'\n",
    "    else:\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir()]\n",
    "        filename='.csv'\n",
    "\n",
    "\n",
    "    \n",
    "    regex1= re.compile('\\d+')\n",
    "    for p in directory:\n",
    "#         filename_avg_c= data_dir+'/'+p+'/avg_corrlen_L100_'+p+'.acl'\n",
    "#         corr=np.loadtxt(filename_avg_c)\n",
    "        \n",
    "        list_files=os.listdir(data_dir+'/'+p)\n",
    "        \n",
    "        \n",
    "        print(data_dir+'/'+p)\n",
    "#         print(corr)\n",
    "#         if corr.size > 0:\n",
    "#             corr=float(corr)\n",
    "       \n",
    "        \n",
    "        list_pkl = [a for a in list_files if \".pkl\" in a]\n",
    "        to_keep = len(list_pkl) - n_to_del\n",
    "        temp = set(random.sample(list_pkl, to_keep))  \n",
    "        new_list_pkl = [file for file in list_pkl if file in temp]  \n",
    "        print('origine list',len(list_pkl),'new list', len(new_list_pkl))\n",
    "        len_pkl=len(new_list_pkl)\n",
    "#         data_corr=np.loadtxt(data_dir+'/'+p+'/corlen_L100_'+p+'.cl',unpack=True)\n",
    "        #seeds=data_corr[0]\n",
    "#         corr_l_list=data_corr[2]\n",
    "        \n",
    "        \n",
    "#         result = np.where(data[0] == 1000446293)\n",
    "\n",
    "        #str(HWTB)+'_'+str(HWLR)+'_'+str(PBCTB)+'_'+str(PBCLR)\n",
    "        \n",
    "        for file_pkl in range(len_pkl):\n",
    "            filename_pkl=new_list_pkl[file_pkl]\n",
    "            \n",
    "            seed=filename_pkl.split('_')[12]       \n",
    "            regex3 = re.compile('\\d+')\n",
    "            seed_reg=re.findall(regex3,seed)\n",
    "            seed_number=int(seed_reg[0])\n",
    "           \n",
    "            #print(seed_number)\n",
    "#             array_index_seed = np.where(seeds == seed_number)\n",
    "#             #print(array_index_seed)\n",
    "#             index_seed=int(array_index_seed[0])\n",
    "#             corr_l=corr_l_list[index_seed]\n",
    "           \n",
    "            \n",
    "            span_1=filename_pkl.split('_')[1]                  \n",
    "            span_reg_1=re.findall(regex1,span_1)\n",
    "            span_1_pkl=int(span_reg_1[0])\n",
    "            \n",
    "            span_0=filename_pkl.split('_')[2]                  \n",
    "            span_reg_0=re.findall(regex1,span_0)\n",
    "            span_0_pkl=int(span_reg_0[0])\n",
    "            \n",
    "            p0=filename_pkl.split('_')[8]  \n",
    "            regex4=re.compile('\\d+\\.\\d+')\n",
    "            p0_reg=re.findall(regex4,p0)\n",
    "            p0_pkl=p0_reg[0]\n",
    "            p0_pkl_final='p'+str(p0_pkl)\n",
    "            \n",
    "            \n",
    "            p1=filename_pkl.split('_')[10]                  \n",
    "            p1_reg=re.findall(regex4,p1)\n",
    "            #print(p1)\n",
    "            p1_pkl=float(p1_reg[0])\n",
    "            p1_pkl_final='p'+str(p1_pkl)\n",
    "            \n",
    "            data_pkl=[filename_pkl,p0_pkl_final,span_1_pkl,p1_pkl_final,span_0_pkl]#,corr_l,corr] \n",
    "            \n",
    "            if 'data_pkl_crosses'+'_'+data_folder+filename in os.listdir('.'):\n",
    "                with open('data_pkl_crosses'+'_'+data_folder+filename, 'a', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "            else:\n",
    "                with open('data_pkl_crosses'+'_'+data_folder+filename, 'w', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "        \n",
    "        \n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_crosses='/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.7\n",
      "origine list 501 new list 501\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.65\n",
      "origine list 500 new list 500\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.15\n",
      "origine list 500 new list 500\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.4\n",
      "origine list 500 new list 500\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.75\n",
      "origine list 500 new list 500\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.85\n",
      "origine list 501 new list 501\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.3\n",
      "origine list 500 new list 500\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.9\n",
      "origine list 501 new list 501\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.1\n",
      "origine list 500 new list 500\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.35\n",
      "origine list 500 new list 500\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.45\n",
      "origine list 500 new list 500\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.6\n",
      "origine list 500 new list 500\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.25\n",
      "origine list 500 new list 500\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.8\n",
      "origine list 501 new list 501\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.2\n",
      "origine list 500 new list 500\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.5\n",
      "origine list 500 new list 500\n",
      "/storage/disqs/ML-Percolation/Data/Crosses/L100_h1-1_v1-1-u0-0_d0-0_A/p0.55\n",
      "origine list 500 new list 500\n"
     ]
    }
   ],
   "source": [
    "generate_csv_pkl_no_c_p_crosses(csv_crosses,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
