{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file='/storage/disqs/ML-Percolation/Data/L100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv_pkl_slice_true_c(data_dir,n_to_del,data_type=None):    \n",
    "    \n",
    "    if data_type=='h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        filename='_h_res.csv'\n",
    "    elif data_type=='very_h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.62]    \n",
    "        filename='_55_62.csv'\n",
    "    \n",
    "    elif data_type=='int':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        directory.append('p0.6')\n",
    "        filename='_int.csv'\n",
    "        \n",
    "    elif data_type=='int_':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.5<float(re.findall(regex2,d.name)[0])]    \n",
    "        filename='_int_0.5.csv'\n",
    "    elif data_type=='h_res_plus':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]\n",
    "        directory.append('p0.5')\n",
    "        directory.append('p0.7')\n",
    "        filename='_h_res_plus.csv'\n",
    "    else:\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir()]\n",
    "        filename='.csv'\n",
    "\n",
    "\n",
    "    \n",
    "    regex1= re.compile('\\d+')\n",
    "    for p in directory:\n",
    "        filename_avg_c= data_dir+'/'+p+'/avg_corrlen_L100_'+p+'.acl'\n",
    "        corr=np.loadtxt(filename_avg_c)\n",
    "        \n",
    "        list_files=os.listdir(data_dir+'/'+p)\n",
    "        \n",
    "        \n",
    "        print(data_dir+'/'+p)\n",
    "        print(corr)\n",
    "        if corr.size > 0:\n",
    "            corr=float(corr)\n",
    "       \n",
    "        \n",
    "        list_pkl = [a for a in list_files if \".pkl\" in a]\n",
    "        to_keep = len(list_pkl) - n_to_del\n",
    "        temp = set(random.sample(list_pkl, to_keep))  \n",
    "        new_list_pkl = [file for file in list_pkl if file in temp]  \n",
    "        print('origine list',len(list_pkl),'new list', len(new_list_pkl))\n",
    "        len_pkl=len(new_list_pkl)\n",
    "        data_corr=np.loadtxt(data_dir+'/'+p+'/corlen_L100_'+p+'.cl',unpack=True)\n",
    "        seeds=data_corr[0]\n",
    "        corr_l_list=data_corr[2]\n",
    "        \n",
    "        \n",
    "#         result = np.where(data[0] == 1000446293)\n",
    "\n",
    "        #str(HWTB)+'_'+str(HWLR)+'_'+str(PBCTB)+'_'+str(PBCLR)\n",
    "        \n",
    "        for file_pkl in range(len_pkl):\n",
    "            filename_pkl=new_list_pkl[file_pkl]\n",
    "            print(new_list_pkl[file_pkl])\n",
    "            \n",
    "            seed=filename_pkl.split('_')[9]       \n",
    "            regex3 = re.compile('\\d+')\n",
    "            seed_reg=re.findall(regex3,seed)\n",
    "            seed_number=int(seed_reg[0])\n",
    "           \n",
    "            print('seed number',seed_number)\n",
    "            array_index_seed = np.where(seeds == seed_number)\n",
    "            print('array',array_index_seed)\n",
    "            index_seed=int(array_index_seed[0])\n",
    "            corr_l=corr_l_list[index_seed]\n",
    "           \n",
    "            \n",
    "            span_0=filename_pkl.split('_')[1]                  \n",
    "            span_reg_0=re.findall(regex1,span_0)\n",
    "            span_pkl=int(span_reg_0[0])\n",
    "            \n",
    "            span_hwtb=filename_pkl.split('_')[2]                  \n",
    "            span_reg_hwtb=re.findall(regex1,span_hwtb)\n",
    "            span_hwtb_pkl=int(span_reg_hwtb[0])\n",
    "            \n",
    "            span_hwlr=filename_pkl.split('_')[3]                  \n",
    "            span_reg_hwlr=re.findall(regex1,span_hwlr)\n",
    "            span_hwlr_pkl=int(span_reg_hwlr[0])\n",
    "            \n",
    "            span_pbctb=filename_pkl.split('_')[4]                  \n",
    "            span_reg_pbctb=re.findall(regex1,span_pbctb)\n",
    "            span_pbctb_pkl=int(span_reg_pbctb[0])\n",
    "            \n",
    "            span_pbclr=filename_pkl.split('_')[5]                  \n",
    "            span_reg_pbclr=re.findall(regex1,span_pbclr)\n",
    "            span_pbclr_pkl=int(span_reg_pbclr[0])\n",
    "            data_pkl=[filename_pkl,p,span_pkl,span_hwtb_pkl,span_hwlr_pkl,span_pbctb_pkl,span_pbclr_pkl,corr_l,corr] \n",
    "            \n",
    "            if 'data_pkl_100_complete_'+str(to_keep)+filename in os.listdir('.'):\n",
    "                with open('data_pkl_100_complete_'+str(to_keep)+filename, 'a', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "            else:\n",
    "                with open('data_pkl_100_complete_'+str(to_keep)+filename, 'w', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "        \n",
    "        \n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_csv_pkl_slice_true_c(csv_file,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file='/storage/disqs/ML-Percolation/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_csv_pkl_slice_true_c(csv_file,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv_pkl_no_c(main_dir,to_keep,size,data_type=None):\n",
    "    data_dir=main_dir+'/L'+str(size)\n",
    "    #os.chdir(data_dir)\n",
    "    #print(os.listdir(data_dir))\n",
    "    if data_type=='h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        filename='_h_res.csv'\n",
    "    elif data_type=='very_h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.62]    \n",
    "        filename='_55_62.csv'\n",
    "    elif data_type=='andreas':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.56<=float(re.findall(regex2,d.name)[0])<=0.61]\n",
    "    \n",
    "        filename='_56_61.csv'\n",
    "    elif data_type=='int':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        directory.append('p0.6')\n",
    "        filename='_int.csv'\n",
    "        \n",
    "    elif data_type=='int_':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.5<float(re.findall(regex2,d.name)[0])]    \n",
    "        filename='_int_0.5.csv'\n",
    "    elif data_type=='h_res_plus':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]\n",
    "        directory.append('p0.5')\n",
    "        directory.append('p0.7')\n",
    "        filename='_h_res_plus.csv'\n",
    "    elif data_type=='all_span':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.7<=float(re.findall(regex2,d.name)[0])]\n",
    "    \n",
    "        filename='_all_span_70_90.csv'\n",
    "    else:\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir()]\n",
    "        filename='.csv'\n",
    "\n",
    "    #print(directory)\n",
    "    \n",
    "    regex1= re.compile('\\d+')\n",
    "    for p in directory:\n",
    "#         filename_avg_c= data_dir+'/'+p+'/avg_corrlen_L100_'+p+'.acl'\n",
    "#         corr=np.loadtxt(filename_avg_c)\n",
    "        \n",
    "        list_files=os.listdir(data_dir+'/'+p)\n",
    "        \n",
    "        \n",
    "        print(data_dir+'/'+p)\n",
    "#         print(corr)\n",
    "#         if corr.size > 0:\n",
    "#             corr=float(corr)\n",
    "       \n",
    "        \n",
    "        list_pkl = [a for a in list_files if \".pkl\" in a]\n",
    "        #to_keep = len(list_pkl) - n_to_del\n",
    "        temp = set(random.sample(list_pkl, to_keep))  \n",
    "        new_list_pkl = [file for file in list_pkl if file in temp]  \n",
    "        print('origine list',len(list_pkl),'new list', len(new_list_pkl))\n",
    "        len_pkl=len(new_list_pkl)\n",
    "#         data_corr=np.loadtxt(data_dir+'/'+p+'/corlen_L100_'+p+'.cl',unpack=True)\n",
    "        #seeds=data_corr[0]\n",
    "#         corr_l_list=data_corr[2]\n",
    "        \n",
    "        \n",
    "#         result = np.where(data[0] == 1000446293)\n",
    "\n",
    "        #str(HWTB)+'_'+str(HWLR)+'_'+str(PBCTB)+'_'+str(PBCLR)\n",
    "        \n",
    "        for file_pkl in range(len_pkl):\n",
    "            filename_pkl=new_list_pkl[file_pkl]\n",
    "            \n",
    "            seed=filename_pkl.split('_')[9]       \n",
    "            regex3 = re.compile('\\d+')\n",
    "            seed_reg=re.findall(regex3,seed)\n",
    "            seed_number=int(seed_reg[0])\n",
    "           \n",
    "            #print(seed_number)\n",
    "#             array_index_seed = np.where(seeds == seed_number)\n",
    "#             #print(array_index_seed)\n",
    "#             index_seed=int(array_index_seed[0])\n",
    "#             corr_l=corr_l_list[index_seed]\n",
    "           \n",
    "            \n",
    "            span_0=filename_pkl.split('_')[1]                  \n",
    "            span_reg_0=re.findall(regex1,span_0)\n",
    "            span_pkl=int(span_reg_0[0])\n",
    "            \n",
    "            span_hwtb=filename_pkl.split('_')[2]                  \n",
    "            span_reg_hwtb=re.findall(regex1,span_hwtb)\n",
    "            span_hwtb_pkl=int(span_reg_hwtb[0])\n",
    "            \n",
    "            span_hwlr=filename_pkl.split('_')[3]                  \n",
    "            span_reg_hwlr=re.findall(regex1,span_hwlr)\n",
    "            span_hwlr_pkl=int(span_reg_hwlr[0])\n",
    "            \n",
    "            span_pbctb=filename_pkl.split('_')[4]                  \n",
    "            span_reg_pbctb=re.findall(regex1,span_pbctb)\n",
    "            span_pbctb_pkl=int(span_reg_pbctb[0])\n",
    "            \n",
    "            span_pbclr=filename_pkl.split('_')[5]                  \n",
    "            span_reg_pbclr=re.findall(regex1,span_pbclr)\n",
    "            span_pbclr_pkl=int(span_reg_pbclr[0])\n",
    "            data_pkl=[filename_pkl,p,span_pkl,span_hwtb_pkl,span_hwlr_pkl,span_pbctb_pkl,span_pbclr_pkl]#,corr_l,corr] \n",
    "            \n",
    "            #print(os.getcwd())\n",
    "            if 'data_pkl_'+str(size)+'_'+str(to_keep)+filename in os.listdir('.'):\n",
    "                with open('data_pkl_'+str(size)+'_'+str(to_keep)+filename, 'a', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "            else:\n",
    "                with open('data_pkl_'+str(size)+'_'+str(to_keep)+filename, 'w', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "        \n",
    "        \n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_csv_pkl_no_c(csv_file,1000,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_csv_pkl_no_c(csv_file,2000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv_pkl_no_c_p(data_dir,n_to_del,data_type=None):    \n",
    "    \n",
    "    if data_type=='h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        filename='_h_res.csv'\n",
    "    elif data_type=='very_h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.62]    \n",
    "        filename='_55_62.csv'\n",
    "    \n",
    "    elif data_type=='int':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        directory.append('p0.6')\n",
    "        filename='_int.csv'\n",
    "        \n",
    "    elif data_type=='int_':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.5<float(re.findall(regex2,d.name)[0])]    \n",
    "        filename='_int_0.5.csv'\n",
    "    elif data_type=='h_res_plus':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]\n",
    "        directory.append('p0.5')\n",
    "        directory.append('p0.7')\n",
    "        filename='_h_res_plus.csv'\n",
    "    elif data_type=='all_span':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.7<=float(re.findall(regex2,d.name)[0])<=0.66]\n",
    "    \n",
    "        filename='_all_span.csv'\n",
    "    elif data_type=='andreas':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.56<=float(re.findall(regex2,d.name)[0])<=0.61]\n",
    "    \n",
    "        filename='_56_61.csv'\n",
    "    else:\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir()]\n",
    "        filename='.csv'\n",
    "\n",
    "\n",
    "    \n",
    "    regex1= re.compile('\\d+')\n",
    "    for p in directory:\n",
    "#         filename_avg_c= data_dir+'/'+p+'/avg_corrlen_L100_'+p+'.acl'\n",
    "#         corr=np.loadtxt(filename_avg_c)\n",
    "        \n",
    "        list_files=os.listdir(data_dir+'/'+p)\n",
    "        \n",
    "        \n",
    "        print(data_dir+'/'+p)\n",
    "#         print(corr)\n",
    "#         if corr.size > 0:\n",
    "#             corr=float(corr)\n",
    "       \n",
    "        \n",
    "        list_pkl = [a for a in list_files if \".pkl\" in a]\n",
    "        to_keep = len(list_pkl) - n_to_del\n",
    "        temp = set(random.sample(list_pkl, to_keep))  \n",
    "        new_list_pkl = [file for file in list_pkl if file in temp]  \n",
    "        print('origine list',len(list_pkl),'new list', len(new_list_pkl))\n",
    "        len_pkl=len(new_list_pkl)\n",
    "#         data_corr=np.loadtxt(data_dir+'/'+p+'/corlen_L100_'+p+'.cl',unpack=True)\n",
    "        #seeds=data_corr[0]\n",
    "#         corr_l_list=data_corr[2]\n",
    "        \n",
    "        \n",
    "#         result = np.where(data[0] == 1000446293)\n",
    "\n",
    "        #str(HWTB)+'_'+str(HWLR)+'_'+str(PBCTB)+'_'+str(PBCLR)\n",
    "        \n",
    "        for file_pkl in range(len_pkl):\n",
    "            filename_pkl=new_list_pkl[file_pkl]\n",
    "            \n",
    "            seed=filename_pkl.split('_')[9]       \n",
    "            regex3 = re.compile('\\d+')\n",
    "            seed_reg=re.findall(regex3,seed)\n",
    "            seed_number=int(seed_reg[0])\n",
    "           \n",
    "            #print(seed_number)\n",
    "#             array_index_seed = np.where(seeds == seed_number)\n",
    "#             #print(array_index_seed)\n",
    "#             index_seed=int(array_index_seed[0])\n",
    "#             corr_l=corr_l_list[index_seed]\n",
    "           \n",
    "            \n",
    "            span_0=filename_pkl.split('_')[1]                  \n",
    "            span_reg_0=re.findall(regex1,span_0)\n",
    "            span_pkl=int(span_reg_0[0])\n",
    "            \n",
    "            span_hwtb=filename_pkl.split('_')[2]                  \n",
    "            span_reg_hwtb=re.findall(regex1,span_hwtb)\n",
    "            span_hwtb_pkl=int(span_reg_hwtb[0])\n",
    "            \n",
    "            span_hwlr=filename_pkl.split('_')[3]                  \n",
    "            span_reg_hwlr=re.findall(regex1,span_hwlr)\n",
    "            span_hwlr_pkl=int(span_reg_hwlr[0])\n",
    "            \n",
    "            span_pbctb=filename_pkl.split('_')[4]                  \n",
    "            span_reg_pbctb=re.findall(regex1,span_pbctb)\n",
    "            span_pbctb_pkl=int(span_reg_pbctb[0])\n",
    "            \n",
    "            span_pbclr=filename_pkl.split('_')[5]                  \n",
    "            span_reg_pbclr=re.findall(regex1,span_pbclr)\n",
    "            span_pbclr_pkl=int(span_reg_pbclr[0])\n",
    "            data_pkl=[filename_pkl,p,span_pkl,span_hwtb_pkl,span_hwlr_pkl,span_pbctb_pkl,span_pbclr_pkl]#,corr_l,corr] \n",
    "            \n",
    "            if 'data_pkl_'+str(p)+'_10_'+str(to_keep)+filename in os.listdir('.'):\n",
    "                with open('data_pkl_'+str(p)+'_10_'+str(to_keep)+filename, 'a', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "            else:\n",
    "                with open('data_pkl_'+str(p)+'_10_'+str(to_keep)+filename, 'w', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "        \n",
    "        \n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_csv_pkl_no_c_p(csv_file,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_csv_pkl_no_c_p(csv_file,5000,data_type='andreas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv_pkl_no_c_p_crosses(data_dir,n_to_del,data_type=None):    \n",
    "    data_folder=data_dir.split('/')[-1] \n",
    "    if data_type=='h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        filename='_h_res.csv'\n",
    "    elif data_type=='very_h_res':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.62]    \n",
    "        filename='_55_62.csv'\n",
    "    \n",
    "    elif data_type=='int':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]    \n",
    "        directory.append('p0.6')\n",
    "        filename='_int.csv'\n",
    "        \n",
    "    elif data_type=='int_':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if not 0.5<float(re.findall(regex2,d.name)[0])]    \n",
    "        filename='_int_0.5.csv'\n",
    "    elif data_type=='h_res_plus':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.55<=float(re.findall(regex2,d.name)[0])<=0.66]\n",
    "        directory.append('p0.5')\n",
    "        directory.append('p0.7')\n",
    "        filename='_h_res_plus.csv'\n",
    "    elif data_type=='all_span':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.7<=float(re.findall(regex2,d.name)[0])<=0.66]\n",
    "    \n",
    "        filename='_all_span.csv'\n",
    "    elif data_type=='andreas':\n",
    "        regex2 = re.compile('\\d+\\.\\d+')\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir() if 0.56<=float(re.findall(regex2,d.name)[0])<=0.61]\n",
    "    \n",
    "        filename='_56_61.csv'\n",
    "    else:\n",
    "        directory=[d.name for d in os.scandir(data_dir) if d.is_dir()]\n",
    "        filename='.csv'\n",
    "\n",
    "\n",
    "    \n",
    "    regex1= re.compile('\\d+')\n",
    "    for p in directory:\n",
    "#         filename_avg_c= data_dir+'/'+p+'/avg_corrlen_L100_'+p+'.acl'\n",
    "#         corr=np.loadtxt(filename_avg_c)\n",
    "        \n",
    "        list_files=os.listdir(data_dir+'/'+p)\n",
    "        \n",
    "        \n",
    "        print(data_dir+'/'+p)\n",
    "#         print(corr)\n",
    "#         if corr.size > 0:\n",
    "#             corr=float(corr)\n",
    "       \n",
    "        \n",
    "        list_pkl = [a for a in list_files if \".pkl\" in a]\n",
    "        to_keep = len(list_pkl) - n_to_del\n",
    "        temp = set(random.sample(list_pkl, to_keep))  \n",
    "        new_list_pkl = [file for file in list_pkl if file in temp]  \n",
    "        print('origine list',len(list_pkl),'new list', len(new_list_pkl))\n",
    "        len_pkl=len(new_list_pkl)\n",
    "#         data_corr=np.loadtxt(data_dir+'/'+p+'/corlen_L100_'+p+'.cl',unpack=True)\n",
    "        #seeds=data_corr[0]\n",
    "#         corr_l_list=data_corr[2]\n",
    "        \n",
    "        \n",
    "#         result = np.where(data[0] == 1000446293)\n",
    "\n",
    "        #str(HWTB)+'_'+str(HWLR)+'_'+str(PBCTB)+'_'+str(PBCLR)\n",
    "        \n",
    "        for file_pkl in range(len_pkl):\n",
    "            filename_pkl=new_list_pkl[file_pkl]\n",
    "            \n",
    "            seed=filename_pkl.split('_')[12]       \n",
    "            regex3 = re.compile('\\d+')\n",
    "            seed_reg=re.findall(regex3,seed)\n",
    "            seed_number=int(seed_reg[0])\n",
    "           \n",
    "            #print(seed_number)\n",
    "#             array_index_seed = np.where(seeds == seed_number)\n",
    "#             #print(array_index_seed)\n",
    "#             index_seed=int(array_index_seed[0])\n",
    "#             corr_l=corr_l_list[index_seed]\n",
    "           \n",
    "            \n",
    "            span_0=filename_pkl.split('_')[1]                  \n",
    "            span_reg_0=re.findall(regex1,span_0)\n",
    "            span_0_pkl=int(span_reg_0[0])\n",
    "            \n",
    "            span_1=filename_pkl.split('_')[2]                  \n",
    "            span_reg_1=re.findall(regex1,span_1)\n",
    "            span_1_pkl=int(span_reg_1[0])\n",
    "            \n",
    "            p0=filename_pkl.split('_')[8]  \n",
    "            regex4=re.compile('\\d+\\.\\d+')\n",
    "            p0_reg=re.findall(regex4,p0)\n",
    "            p0_pkl=p0_reg[0]\n",
    "            \n",
    "            \n",
    "            p1=filename_pkl.split('_')[10]                  \n",
    "            p1_reg=re.findall(regex4,p1)\n",
    "            print(p1)\n",
    "            p1_pkl=float(p1_reg[0])\n",
    "            \n",
    "            \n",
    "            data_pkl=[filename_pkl,p1_pkl,span_1_pkl,p0_pkl,span_0_pkl]#,corr_l,corr] \n",
    "            \n",
    "            if 'data_pkl_crosses'+'_'+data_folder+'_'+filename in os.listdir('.'):\n",
    "                with open('data_pkl_crosses'+'_'+data_folder+'_'+filename, 'a', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "            else:\n",
    "                with open('data_pkl_crosses'+'_'+data_folder+'_'+filename, 'w', newline='') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(data_pkl)\n",
    "        \n",
    "        \n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_crosses='/storage/disqs/ML-Percolation/Data/Crosses/L100_h0-0_v0-0-u1-1_d1-1_A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_csv_pkl_no_c_p_crosses(csv_crosses,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
