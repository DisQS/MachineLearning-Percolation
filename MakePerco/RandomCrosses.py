{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percolation_density: workin on p= 0.1\n",
      "Successfully created the directory : p0.1\n",
      "check: max_seed, nbre_file = 0 0\n",
      "--- found seeds= []\n",
      "percolation_density: configs existing, wanted, tomake= 0 1 1\n",
      "percolation: new percolation starting with seed= 890576540\n",
      "--- working in image 0 2022-06-24 01:15:32.812415\n",
      "lattice_config START 2022-06-24 01:15:32.812614\n",
      "lattice_config END 2022-06-24 01:15:32.812730\n",
      "occupied 40\n",
      "Hoshen-Kopelman PBS START 2022-06-24 01:15:32.813074\n",
      "Hoshen-Kopelman PBC END 2022-06-24 01:15:32.813491\n",
      "Hoshen-Kopelman HW START 2022-06-24 01:15:32.813517\n",
      "Hoshen-Kopelman HW END 2022-06-24 01:15:32.813811\n",
      "PBC characterization 2022-06-24 01:15:32.813835\n",
      "HW characterization 2022-06-24 01:15:32.814338\n",
      "PBC coloring 2022-06-24 01:15:32.814508\n",
      "n clusters pbc 27\n",
      "n clusters 28\n",
      "before pbc 20\n",
      "2 [[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "size_blank_pbc 21\n",
      "before 20\n",
      "19\n",
      "size_blank 21\n",
      "before pbc 19\n",
      "2 [[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "size_blank_pbc 20\n",
      "before 19\n",
      "18\n",
      "size_blank 20\n",
      "HW coloring 2022-06-24 01:15:32.816769\n",
      "32\n",
      "max clus 7\n",
      "0.007346153259277344\n",
      "--- NEW configuration 890576540  was created\n",
      "--> 1 new images were created\n",
      "percolation_density: workin on p= 0.2\n",
      "Successfully created the directory : p0.2\n",
      "check: max_seed, nbre_file = 0 0\n",
      "--- found seeds= []\n",
      "percolation_density: configs existing, wanted, tomake= 0 1 1\n",
      "percolation: new percolation starting with seed= 3711217784\n",
      "--- working in image 0 2022-06-24 01:15:32.822438\n",
      "lattice_config START 2022-06-24 01:15:32.822473\n",
      "lattice_config END 2022-06-24 01:15:32.822824\n",
      "occupied 80\n",
      "Hoshen-Kopelman PBS START 2022-06-24 01:15:32.822904\n",
      "Hoshen-Kopelman PBC END 2022-06-24 01:15:32.823624\n",
      "Hoshen-Kopelman HW START 2022-06-24 01:15:32.823992\n",
      "Hoshen-Kopelman HW END 2022-06-24 01:15:32.824520\n",
      "PBC characterization 2022-06-24 01:15:32.824543\n",
      "HW characterization 2022-06-24 01:15:32.824623\n",
      "PBC coloring 2022-06-24 01:15:32.825005\n",
      "n clusters pbc 50\n",
      "n clusters 52\n",
      "before pbc 20\n",
      "1 [[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "size_blank_pbc 20\n",
      "before 20\n",
      "19\n",
      "size_blank 20\n",
      "before pbc 19\n",
      "0 []\n",
      "size_blank_pbc 18\n",
      "before 19\n",
      "18\n",
      "size_blank 18\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 324 into shape (20,20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3260a23b5a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;31m# %%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m \u001b[0mpercolation_density\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperco_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m#1: number of images for a given p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m#2:list of p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-3260a23b5a15>\u001b[0m in \u001b[0;36mpercolation_density\u001b[0;34m(number_configs, perco_list, lattice_size)\u001b[0m\n\u001b[1;32m    499\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--- NEW seed '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' scheduled to be made'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m                     \u001b[0;31m# now we have a good seed, let's percolate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m                 \u001b[0mperco_calcul\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpercolation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlattice_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m                 \u001b[0mconfigs_created\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[0mconfigs_tomake\u001b[0m\u001b[0;34m-=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-3260a23b5a15>\u001b[0m in \u001b[0;36mpercolation\u001b[0;34m(im, p, size_sys, seed, max_thick, nb_hlines, nb_vlines)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;31m################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         cluster_blank_pbc_int= np.array([new_mapping_pbc[v]+1 \\\n\u001b[0m\u001b[1;32m    366\u001b[0m                             if not v == -1 else 0 for v in cluster_blank_pbc.flat]).reshape(size_sys,size_sys)\n\u001b[1;32m    367\u001b[0m         cluster_blank_pbc_norm = np.array([(new_mapping_pbc[v]+1)/n_clusters_pbc \\\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 324 into shape (20,20)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import random\n",
    "import os\n",
    "import imageio\n",
    "import binascii\n",
    "import sys\n",
    "import time \n",
    "import datetime\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "###############################################################################\n",
    "def check_name(path):\n",
    "    import re\n",
    "    results=[]\n",
    "    seeds=[]\n",
    "   \n",
    "    for files in os.listdir(path):\n",
    "        if files.endswith('info.txt'):\n",
    "            results.append(files)\n",
    "            seed_sys=files.split('_')[9]      \n",
    "            regex3 = re.compile('\\d+')\n",
    "            seed_sys_reg=re.findall(regex3,seed_sys)\n",
    "            seeds.append(int(seed_sys_reg[0]))\n",
    "    \n",
    "    nbre_files=len(results)\n",
    "    if len(seeds)>0:\n",
    "        max_seed=max(seeds)\n",
    "    else:\n",
    "        max_seed=0\n",
    "\n",
    "    print('check: max_seed, nbre_file =', max_seed, nbre_files)\n",
    "    return max_seed, seeds, nbre_files\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "def create_directory(path):\n",
    "    import os\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory failed, existing file with the same name : \"+str(path))\n",
    "    else:\n",
    "        print (\"Successfully created the directory : \"+str(path))\n",
    "    \n",
    "    return\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def lattice_config(size,seed,p):\n",
    "    print(\"lattice_config START\", datetime.datetime.now())\n",
    "    seed1=np.random.seed(seed)\n",
    "    number_occupied=(size*size)*p\n",
    "    \n",
    "    lattice=np.zeros((size,size), dtype=int)\n",
    "    occupied=0\n",
    "   \n",
    "    while occupied < number_occupied:\n",
    "        \n",
    "        i=random.randint(0,size-1)\n",
    "        j=random.randint(0,size-1)\n",
    "        if lattice[i,j]==0:\n",
    "            lattice[i,j]=1\n",
    "            occupied+=1\n",
    "\n",
    "    print(\"lattice_config END\", datetime.datetime.now())\n",
    "    return lattice, number_occupied\n",
    "\n",
    "###############################################################################       \n",
    "\n",
    "def cluster_matrix(x, y, n_clusters, N, lattice,cluster, sizes):\n",
    "    stack=[(x,y)]\n",
    "\n",
    "    while len(stack)>0:\n",
    "\n",
    "        x,y=stack.pop(-1)\n",
    "\n",
    "        if lattice[x,y] == 1 and cluster[x,y]==-1:\n",
    "            cluster[x,y] = n_clusters\n",
    "            sizes[n_clusters] += 1     #augmente le nombre de site du cluster\n",
    "            if y+1 < N:\n",
    "                stack.append((x,y+1))\n",
    "\n",
    "            if y-1 >= 0:\n",
    "\n",
    "                stack.append((x,y-1))\n",
    "\n",
    "            if x+1 < N:\n",
    "\n",
    "                stack.append((x+1,y))\n",
    "\n",
    "            if x-1 >= 0:\n",
    "                stack.append((x-1,y))\n",
    "\n",
    "\n",
    "################################################################\n",
    "\n",
    "def cluster_matrix_pbc(x, y, n_clusters, N, lattice,cluster, sizes):\n",
    "    stack=[(x,y)]\n",
    "\n",
    "    while len(stack)>0:\n",
    "\n",
    "        x,y=stack.pop(-1)\n",
    "\n",
    "        if lattice[x%N,y%N] == 1 and cluster[x%N,y%N]==-1:\n",
    "            cluster[x%N,y%N] = n_clusters\n",
    "            sizes[n_clusters] += 1     #augmente le nombre de site du cluster\n",
    "\n",
    "            stack.append((x,(y+1%N)))\n",
    "\n",
    "            stack.append((x,(y-1)%N))\n",
    "\n",
    "            stack.append(((x+1)%N,y))\n",
    "\n",
    "            stack.append(((x-1)%N,y))\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "def pbc_percolation(boundary_set,boundary_array_1, boundary_array_2,PBC):\n",
    "    cluster_number=0\n",
    "    for element in boundary_set:\n",
    "        cluster_number=element\n",
    "\n",
    "        new_array=np.array([v if  v == cluster_number else 0 for v in boundary_array_1])\n",
    "\n",
    "        coord_non_zero=new_array.nonzero()[0]\n",
    "\n",
    "        for arg in coord_non_zero:\n",
    "\n",
    "            if  boundary_array_2[arg]!=0:\n",
    "                PBC=1\n",
    "                \n",
    "    return PBC\n",
    "\n",
    "###############################################################################\n",
    "def size_spanning_cluster_old(spanning_set, cluster):\n",
    "    \n",
    "    size_spanning=0\n",
    "    nnz1=cluster.nonzero()\n",
    "    for k in range(len(spanning_set)):\n",
    "        for i, j in zip(*nnz1):\n",
    "            if cluster[i,j] ==list(spanning_set)[k]:\n",
    "                size_spanning+=1\n",
    "                \n",
    "    return size_spanning\n",
    "    \n",
    "##############################################################################\n",
    "def size_spanning_cluster(spanning_set,cluster,cluster_pbc_int):\n",
    "   \n",
    "    size=[]\n",
    "    size_spanning=0\n",
    "    span=list(spanning_set)\n",
    "    n_cluster_pbc_int, counts = np.unique(cluster_pbc_int, return_counts=True)\n",
    "    zip_lists=list(zip( n_cluster_pbc_int, counts))\n",
    "    for k in range(len(spanning_set)):\n",
    "        for i in range(len(zip_lists)):\n",
    "            if zip_lists[i][0]==span[k]:\n",
    "                size.append(zip_lists[i][1])\n",
    "    if len(size)>1:\n",
    "        size_spanning=max(size)\n",
    "        \n",
    "    return size_spanning\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "def mapping_cluster(cluster_nan,cluster_pbc_int,n_perco):\n",
    "\n",
    "    mapping = dict(zip(cluster_nan.flat,cluster_pbc_int.flat))\n",
    "    keys_mapping=mapping.keys()\n",
    "    values_mapping=mapping.values()\n",
    "    v=[p for p in values_mapping if p!=0]\n",
    "    k=list(filter(lambda v: v==v, keys_mapping))\n",
    "    zip_keys_values=list(zip(k,v))\n",
    "    new_n=[]\n",
    "    \n",
    "    for i in range(0,len(zip_keys_values)):\n",
    "        if (zip_keys_values[i][0] in n_perco) and (zip_keys_values[i][1] not in new_n):\n",
    "            new_n.append(zip_keys_values[i][1])\n",
    "\n",
    "    return new_n\n",
    "    \n",
    "\n",
    "###############################################################################\n",
    "def percolation(im,p,size_sys,seed,max_thick,nb_hlines=1,nb_vlines=1):\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    # the seed has alreayd been checked to see if it's ok\n",
    "    # but it also means we should only use it for im=1\n",
    "    print('percolation: new percolation starting with seed=', seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    #create_directory('percolating')   #if we want to classify them inside each density directory\n",
    "    #create_directory('not_percolating')\n",
    "    \n",
    "    for t in range(im):\n",
    "        print('--- working in image', t, datetime.datetime.now())\n",
    "        start2=time.time()\n",
    "        lattice_para=lattice_config(size_sys,seed,p)\n",
    "\n",
    "        \n",
    "        occupied = lattice_para[0].nonzero()\n",
    "        print('occupied',len(list(zip(*occupied))))\n",
    "        n_clusters_pbc = 0\n",
    "        n_clusters = 0\n",
    "        cluster_pbc=np.zeros((size_sys,size_sys), dtype=int)-1\n",
    "        cluster=np.zeros((size_sys,size_sys), dtype=int)-1\n",
    "        sizes_pbc = Counter()\n",
    "        sizes = Counter()\n",
    "#         print('cluster')\n",
    "        print(\"Hoshen-Kopelman PBS START\", datetime.datetime.now())\n",
    "        for i, j in zip(*occupied):\n",
    "            if cluster_pbc[i,j] == -1:\n",
    "                cluster_matrix_pbc(i, j, n_clusters_pbc, size_sys,lattice_para[0],cluster_pbc, sizes_pbc)\n",
    "\n",
    "                n_clusters_pbc += 1\n",
    "        print(\"Hoshen-Kopelman PBC END\", datetime.datetime.now())\n",
    "        \n",
    "        print(\"Hoshen-Kopelman HW START\", datetime.datetime.now())\n",
    "        for i, j in zip(*occupied):\n",
    "            if cluster[i,j] == -1:\n",
    "                cluster_matrix(i, j, n_clusters, size_sys,lattice_para[0],cluster, sizes)\n",
    "\n",
    "                n_clusters += 1\n",
    "                #print(n_clusters)\n",
    "        print(\"Hoshen-Kopelman HW END\", datetime.datetime.now())\n",
    "        \n",
    "        print(\"PBC characterization\", datetime.datetime.now())\n",
    "            \n",
    "        order_pbc=OrderedDict(sizes_pbc.most_common())\n",
    "                  \n",
    "        classification_pbc=list(order_pbc)\n",
    "        #print(order)\n",
    "        \n",
    "        numbers_pbc = np.arange(0,n_clusters_pbc)\n",
    "        weight_pbc=-np.sort(-(numbers_pbc))\n",
    "        k_pbc=list(zip(classification_pbc,weight_pbc))\n",
    "        \n",
    "        correspondance_pbc=sorted(k_pbc, key = lambda t: t[0])\n",
    "        unzip_pbc=list(zip(*correspondance_pbc))\n",
    "        new_mapping_pbc=unzip_pbc[1]\n",
    "        \n",
    "        \n",
    "        print(\"HW characterization\", datetime.datetime.now())\n",
    "        \n",
    "        order=OrderedDict(sizes.most_common())\n",
    "                  \n",
    "        classification=list(order)\n",
    "        \n",
    "        \n",
    "        numbers = np.arange(0,n_clusters)\n",
    "        weight=-np.sort(-(numbers))\n",
    "        k=list(zip(classification,weight))\n",
    "        \n",
    "        correspondance=sorted(k, key = lambda t: t[0])\n",
    "        unzip=list(zip(*correspondance))\n",
    "        \n",
    "        new_mapping=unzip[1]\n",
    "\n",
    "        print(\"PBC coloring\", datetime.datetime.now())\n",
    "\n",
    "        print('n clusters pbc',n_clusters_pbc)\n",
    "        print('n clusters',n_clusters)\n",
    "        \n",
    "        coord_hlines=[]\n",
    "        thick_hlines=[]\n",
    "        coord_vlines=[]\n",
    "        thick_vlines=[]\n",
    "        for hline in range(nb_hlines):\n",
    "            hline=random.randint(0,size_sys-1)\n",
    "            thline=random.randint(0,size_sys-1)\n",
    "            coord_hlines.append(hline)\n",
    "            thick_hlines.append(thline)\n",
    "            space=random.randint(0,max_thick)\n",
    "##################################################################################################################PBC\n",
    "            print('before pbc',len(cluster_pbc))\n",
    "            cluster_pbc=np.delete(cluster_pbc,hline,1)\n",
    "            cluster_pbc=np.delete(cluster_pbc,hline,0)\n",
    "            col=np.zeros((len(cluster_pbc),space), dtype='int')-1\n",
    "            cluster_blank_pbc=np.c_[cluster_pbc[:,:hline],col,cluster_pbc[:,hline:]]\n",
    "            row=np.zeros((space,len(cluster_blank_pbc[0])), dtype='int')-1\n",
    "\n",
    "            print(len(row),row)\n",
    "\n",
    "            cluster_blank_pbc=np.r_[cluster_blank_pbc[:hline,:],row,cluster_blank_pbc[hline:,:]]\n",
    "            size_blank_pbc=len(cluster_blank_pbc)\n",
    "            print('size_blank_pbc', size_blank_pbc)\n",
    "###################################################################################################################HW\n",
    "            print('before',len(cluster))\n",
    "            cluster=np.delete(cluster,hline,1)\n",
    "            cluster=np.delete(cluster,hline,0)\n",
    "            print( len(cluster))\n",
    "            cluster_blank=np.c_[cluster[:,:hline],col,cluster[:,hline:]]\n",
    "            row=np.zeros((space,len(cluster_blank[0])), dtype='int')-1\n",
    "            cluster_blank=np.r_[cluster_blank[:hline,:],row,cluster_blank[hline:,:]]\n",
    "            size_blank=len(cluster_blank)\n",
    "            print('size_blank', size_blank)\n",
    "            \n",
    "        for vline in range(nb_vlines):\n",
    "            vline=random.randint(0,size_sys-1)\n",
    "            tvline=random.randint(0,size_sys-1)\n",
    "            coord_vlines.append(vline)\n",
    "            thick_vlines.append(tvline)\n",
    "            space=random.randint(0,max_thick)\n",
    "##################################################################################################################PBC\n",
    "            print('before pbc',len(cluster_pbc))\n",
    "            cluster_pbc=np.delete(cluster_pbc,vline,1)\n",
    "            cluster_pbc=np.delete(cluster_pbc,vline,0)\n",
    "            col=np.zeros((len(cluster_pbc),space), dtype='int')-1\n",
    "            cluster_blank_pbc=np.c_[cluster_pbc[:,:vline],col,cluster_pbc[:,vline:]]\n",
    "            row=np.zeros((space,len(cluster_blank_pbc[0])), dtype='int')-1\n",
    "\n",
    "            print(len(row),row)\n",
    "\n",
    "            cluster_blank_pbc=np.r_[cluster_blank_pbc[:vline,:],row,cluster_blank_pbc[vline:,:]]\n",
    "            size_blank_pbc=len(cluster_blank_pbc)\n",
    "            print('size_blank_pbc', size_blank_pbc)\n",
    "###################################################################################################################HW\n",
    "            print('before',len(cluster))\n",
    "            cluster=np.delete(cluster,vline,1)\n",
    "            cluster=np.delete(cluster,vline,0)\n",
    "            print( len(cluster))\n",
    "            cluster_blank=np.c_[cluster[:,:vline],col,cluster[:,vline:]]\n",
    "            row=np.zeros((space,len(cluster_blank[0])), dtype='int')-1\n",
    "            cluster_blank=np.r_[cluster_blank[:vline,:],row,cluster_blank[vline:,:]]\n",
    "            size_blank=len(cluster_blank)\n",
    "            print('size_blank', size_blank)\n",
    "          \n",
    "            \n",
    "        \n",
    "############################################ For PBC\n",
    "#        print('before pbc',len(cluster_pbc))\n",
    "#        \n",
    "#        cluster_pbc=np.delete(cluster_pbc,mid,1)\n",
    "#        cluster_pbc=np.delete(cluster_pbc,mid,0)\n",
    "#        col=np.zeros((len(cluster_pbc),space), dtype='int')-1\n",
    "#     \n",
    "#        print(col)\n",
    "#        print( len(cluster_pbc))\n",
    "#        cluster_blank_pbc=np.c_[cluster_pbc[:,:mid],col,cluster_pbc[:,mid:]]\n",
    "#        row=np.zeros((space,len(cluster_blank_pbc[0])), dtype='int')-1\n",
    "#\n",
    "#        print(len(row),row)\n",
    "#\n",
    "#        cluster_blank_pbc=np.r_[cluster_blank_pbc[:mid,:],row,cluster_blank_pbc[mid:,:]]\n",
    "#        size_blank_pbc=len(cluster_blank_pbc)\n",
    "#        print('size_blank_pbc', size_blank_pbc)\n",
    "#\n",
    "############################################ For HW\n",
    "\n",
    "#        print('before',len(cluster))\n",
    "#        cluster=np.delete(cluster,mid,1)\n",
    "#        cluster=np.delete(cluster,mid,0)\n",
    "#        print( len(cluster))\n",
    "#        cluster_blank=np.c_[cluster[:,:mid],col,cluster[:,mid:]]\n",
    "#        row=np.zeros((space,len(cluster_blank[0])), dtype='int')-1\n",
    "#        cluster_blank=np.r_[cluster_blank[:mid,:],row,cluster_blank[mid:,:]]\n",
    "#        size_blank=len(cluster_blank)\n",
    "#        print('size_blank', size_blank)\n",
    "################################################\n",
    "        \n",
    "        cluster_blank_pbc_int= np.array([new_mapping_pbc[v]+1 \\\n",
    "                            if not v == -1 else 0 for v in cluster_blank_pbc.flat]).reshape(size_sys,size_sys)\n",
    "        cluster_blank_pbc_norm = np.array([(new_mapping_pbc[v]+1)/n_clusters_pbc \\\n",
    "                            if not v == -1 else 0 for v in cluster_blank_pbc.flat]).reshape(size_sys,size_sys)\n",
    "        cluster_blank_pbc_nan= np.array([new_mapping_pbc[v]+1 \\\n",
    "                            if not v == -1 else np.nan for v in cluster_blank_pbc.flat]).reshape(size_sys,size_sys)\n",
    "        \n",
    "        \n",
    "        print(\"HW coloring\", datetime.datetime.now())\n",
    "        \n",
    "        cluster_blank_int= np.array([new_mapping[v]+1 \\\n",
    "                            if not v == -1 else 0 for v in cluster_blank.flat]).reshape(size_sys,size_sys)\n",
    "        cluster_blank_norm = np.array([(new_mapping[v]+1)/n_clusters \\\n",
    "                            if not v == -1 else 0 for v in cluster_blank.flat]).reshape(size_sys,size_sys)\n",
    "        cluster_blank_nan = np.array([new_mapping[v]+1\\\n",
    "                           if not v == -1 else np.nan for v in cluster_blank.flat]).reshape(size_sys,size_sys)\n",
    "\n",
    "        p1=len(list(zip(*cluster_blank_int.nonzero())))\n",
    "        print(p1)\n",
    "        \n",
    "        all_sizes_pbc = Counter(list(sizes_pbc.values()))\n",
    "        \n",
    "        #get size of largest cluster\n",
    "        if n_clusters_pbc !=0:\n",
    "            max_size_pbc = max(all_sizes_pbc.keys())\n",
    "        \n",
    "        occ=len(list(zip(*cluster_blank_int.nonzero())))\n",
    "        start4=time.time()\n",
    "        proba_largest=(max_size_pbc/(size_sys**2))**2\n",
    "\n",
    "        square_proba=p*p\n",
    "\n",
    "       \n",
    "        print('max clus', max_size_pbc)\n",
    "        end4=time.time()-start4\n",
    "\n",
    "        occ=len(list(zip(*cluster_blank_int.nonzero())))\n",
    "\n",
    "        top=cluster_blank_nan[0][:]\n",
    "        bottom=cluster_blank_nan[-1][:]\n",
    "        left=cluster_blank_nan[:,0]\n",
    "        right=cluster_blank_nan[:,-1]\n",
    "       \n",
    "        top_bot_inter=set(x for x in cluster_blank_nan[0][:]).intersection(set(y for y in cluster_blank_nan[-1][:]))\n",
    "        sides_inter=set(w for w in cluster_blank_nan[:,0]).intersection(set(z for z in cluster_blank_nan[:,-1]))\n",
    "        \n",
    "        \n",
    "        HWTB=0\n",
    "        HWLR=0\n",
    "        PBCTB=0\n",
    "        PBCLR=0\n",
    "        \n",
    "        size_side_spanning_pbc=0\n",
    "        size_top_spanning_pbc=0\n",
    "        size_top_side_spanning_pbc=0\n",
    "        rgba1=0\n",
    "        rgba2=0\n",
    "         \n",
    "        \n",
    "            \n",
    "        filename0='pc_0_0_'+str(HWTB)+'_'+str(HWLR)+'_'+str(PBCTB)+'_'+str(PBCLR)+'__p'+str(p1)+'_L'+str(size_sys)+'_s'+str(seed)+\\\n",
    "                        '_nc'+str(n_clusters_pbc)+'_smc'+str(max_size_pbc)+'_n'+str(n_clusters_pbc)\n",
    "\n",
    "\n",
    "        text_file0=open(filename0+'.txt', \"w+\")\n",
    "        text_file0.write('Total number of cluster= '+ repr(n_clusters_pbc)+'\\n')\n",
    "        text_file0.write('Size of the largest cluster (number of site occupied)= '+ repr(max_size_pbc)+'\\n')\n",
    "        text_file0.write('Sizes of each clusters (number associated to the cluster: number of occupied sites)= ' +repr(sizes)+\"\\n\")\n",
    "        text_file0.close()\n",
    "\n",
    "        data_pkl0 = {'cluster_pbc_int' : cluster_blank_pbc_int ,\n",
    "                   'cluster_pbc_norm' : cluster_blank_pbc_norm,\n",
    "                   'n_clusters_pbc':n_clusters_pbc,\n",
    "                   'cluster_int':cluster_blank_int,\n",
    "                   'cluster_norm':cluster_blank_norm,\n",
    "                   'proba largest' : proba_largest,\n",
    "                   'square proba':square_proba,\n",
    "                   'size max cluster':max_size_pbc,\n",
    "                   'p0':p,\n",
    "                   'p1':p1,\n",
    "                   'nb_vlines':nb_vlines,\n",
    "                   'nb_hlines':nb_hlines,\n",
    "                   'coord_hlines':coord_hlines,\n",
    "                   'thick_hlines':thick_hlines,\n",
    "                   'coord_vlines':coord_vlines,\n",
    "                   'thick_vlines':thick_vlines}\n",
    "            \n",
    "        pkl_file0=open(filename0+'.pkl', \"wb\")\n",
    "        pickle.dump(data_pkl0 ,pkl_file0)\n",
    "        pkl_file0.close()\n",
    "            \n",
    "        end2=time.time()-start2\n",
    "        print(end2)\n",
    "\n",
    "    return cluster,n_clusters,cluster_blank_pbc,n_clusters_pbc, sizes_pbc,lattice_para[0],new_mapping,order,order_pbc,occ,\\\n",
    "sizes,cluster_blank_int, top_bot_inter,sides_inter,cluster_blank_nan\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "def percolation_density(number_configs,perco_list,lattice_size):  \n",
    "    import os\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    dens=[]\n",
    "    start1= time.time()\n",
    "    configs_wanted=number_configs\n",
    "    #seed=int(binascii.hexlify(os.urandom(4)),16)\n",
    "    for p in perco_list:\n",
    "        print('percolation_density: workin on p=', p)\n",
    "\n",
    "        configs_created=0\n",
    "        \n",
    "        if os.path.exists('p'+str(p)) and len(os.listdir('p'+str(p)))!=0:\n",
    "            print('A directory '+'p='+str(p)+' already exists')\n",
    "        else:\n",
    "            create_directory('p'+str(p))\n",
    "        \n",
    "        os.chdir('p'+str(p))\n",
    "\n",
    "        max_seed,seeds_existing,configs_existing=check_name('.')\n",
    "        print('--- found seeds=', seeds_existing)\n",
    "\n",
    "        if configs_wanted >= configs_existing:  #nbre_images:\n",
    "            configs_tomake = configs_wanted - configs_existing   #nbre_images\n",
    "            print('percolation_density: configs existing, wanted, tomake=',configs_existing, configs_wanted, configs_tomake)\n",
    "            while configs_tomake > 0:\n",
    "                seed=int(binascii.hexlify(os.urandom(4)),16)\n",
    "                if seed in seeds_existing: #seed_list:\n",
    "                    print('Image with seed = ',seed, 'already exists')\n",
    "                    while seed in seeds_existing:\n",
    "                        seed=int(binascii.hexlify(os.urandom(4)),16)\n",
    "                    seeds_existing.append(seed)\n",
    "                    print('--- NEW seed ', seed, ' scheduled to be made')\n",
    "                    # now we have a good seed, let's percolate\n",
    "                perco_calcul= percolation(1,p,lattice_size,seed,2)\n",
    "                configs_created+=1\n",
    "                configs_tomake-=1\n",
    "                print('--- NEW configuration', seed,' was created')\n",
    "\n",
    "            os.chdir('..')\n",
    "            if configs_created!=0:\n",
    "                print(\"-->\",configs_created, 'new images were created')\n",
    "        \n",
    "    end1=time.time()\n",
    "    total_time=end1-start1\n",
    "    print(\"Images generated in : \", total_time, \"seconds\")\n",
    "    return \n",
    "\n",
    "####################################################################################################################\n",
    "# if ( len(sys.argv) == 6 ):\n",
    "#     #SEED = 101\n",
    "#     #SEED = int(sys.argv[1])\n",
    "#     lattice_size = 10 #int(sys.argv[1])\n",
    "#     perco_init =1000 # int(sys.argv[2]) \n",
    "#     perco_final = 4000# int(sys.argv[3])\n",
    "#     perco_inc = 1000#int(sys.argv[4])\n",
    "#     number_configs = 1#int(sys.argv[5])\n",
    "\n",
    "perco_list=[val/10000 for val in range(1000,4000+1,1000)]\n",
    "            \n",
    "    # %%\n",
    "percolation_density(1,perco_list,20) \n",
    "    #1: number of images for a given p\n",
    "    #2:list of p\n",
    "    #3: side length of the square lattice\n",
    "    #4: seed \n",
    "\n",
    "# else:\n",
    "#     print ('Number of', len(sys.argv), \\\n",
    "#            'arguments is less than expected (6) --- ABORTING!')\n",
    "#     print ('Usage: python '+sys.argv[0],\\\n",
    "#            '  size p_initial*10000 p_final*10000 dp*10000 number_of_configurations')\n",
    "#     #print ('Argument List:', str(sys.argv))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
